{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14989262,"datasetId":9594780,"databundleVersionId":15863284}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ThePyProgrammer/RageAgainstTheMachine\n!cp -r RageAgainstTheMachine/ml/* .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:14:45.045230Z","iopub.execute_input":"2026-02-28T07:14:45.045518Z","iopub.status.idle":"2026-02-28T07:15:33.634602Z","shell.execute_reply.started":"2026-02-28T07:14:45.045493Z","shell.execute_reply":"2026-02-28T07:15:33.633623Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'RageAgainstTheMachine'...\nremote: Enumerating objects: 1184, done.\u001b[K\nremote: Counting objects: 100% (441/441), done.\u001b[K\nremote: Compressing objects: 100% (304/304), done.\u001b[K\nremote: Total 1184 (delta 160), reused 352 (delta 113), pack-reused 743 (from 1)\u001b[K\nReceiving objects: 100% (1184/1184), 334.58 MiB | 23.91 MiB/s, done.\nResolving deltas: 100% (318/318), done.\nUpdating files: 100% (759/759), done.\nFiltering content: 100% (10/10), 320.50 MiB | 11.40 MiB/s, done.\nEncountered 34 file(s) that should have been pointers, but weren't:\n\tbackend/external/rPPG-Toolbox/dataset/data_loader/face_detector/ckpts/Y5sF_WFRGB.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_BigSmall_Multitask_Fold1.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_BigSmall_Multitask_Fold2.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_BigSmall_Multitask_Fold3.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_PseudoLabel_DeepPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_PseudoLabel_EfficientPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_PseudoLabel_PhysNet_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/BP4D_PseudoLabel_TSCAN.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/MA-UBFC_deepphys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/MA-UBFC_efficientphys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/MA-UBFC_physnet.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/MA-UBFC_tscan.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_DeepPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_EfficientPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_FactorizePhys_FSAM_Res.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_PhysFormer_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_PhysMamba_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_PhysNet_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_RhythmFormer.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_TSCAN.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/PURE_iBVPNet.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_DeepPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_EfficientPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_FactorizePhys_FSAM_Res.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_PhysFormer_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_PhysNet_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/SCAMPS_TSCAN.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_DeepPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_EfficientPhys.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_FactorizePhys_FSAM_Res.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_PhysFormer_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_PhysMamba_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_PhysNet_DiffNormalized.pth\n\tbackend/external/rPPG-Toolbox/final_model_release/UBFC-rPPG_RhythmFormer.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!cp -r /kaggle/input/datasets/prannayagupta/eegmmidb .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:15:33.636398Z","iopub.execute_input":"2026-02-28T07:15:33.636893Z","iopub.status.idle":"2026-02-28T07:15:39.733897Z","shell.execute_reply.started":"2026-02-28T07:15:33.636863Z","shell.execute_reply":"2026-02-28T07:15:39.733127Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom scipy import signal\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:15:39.735133Z","iopub.execute_input":"2026-02-28T07:15:39.735389Z","iopub.status.idle":"2026-02-28T07:15:44.060531Z","shell.execute_reply.started":"2026-02-28T07:15:39.735364Z","shell.execute_reply":"2026-02-28T07:15:44.059956Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from eeg.dataset import PhysioNetDataset, preprocess_eeg\nfrom utils.config_loader import get_project_root, load_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:15:44.061933Z","iopub.execute_input":"2026-02-28T07:15:44.062268Z","iopub.status.idle":"2026-02-28T07:15:45.214247Z","shell.execute_reply.started":"2026-02-28T07:15:44.062246Z","shell.execute_reply":"2026-02-28T07:15:45.213468Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def _resample_epochs(X: np.ndarray, original_fs: int, target_fs: int) -> np.ndarray:\n    if original_fs == target_fs:\n        return X\n    n_samples_target = int(X.shape[-1] * target_fs / original_fs)\n    return signal.resample(X, n_samples_target, axis=-1)\n\n\ndef _is_all_channels(channels: str | list[str]) -> bool:\n    if isinstance(channels, str):\n        return channels.lower() == \"all\"\n    return len(channels) == 1 and channels[0].lower() == \"all\"\n\n\ndef prepare_data(config: dict):\n    \"\"\"Download and prepare dataset with subject-level train/val split.\"\"\"\n    print(\"=\" * 60)\n    print(\"PREPARING DATASET (LaBraM Probe)\")\n    print(\"=\" * 60)\n\n    dataset_config = config[\"dataset\"]\n    train_subjects = dataset_config[\"train_subjects\"]\n    val_subjects = dataset_config[\"val_subjects\"]\n    runs = dataset_config[\"runs\"]\n    event_keys = dataset_config.get(\"event_keys\", [\"T0\", \"T1\", \"T2\"])\n\n    print(f\"\\n  Training subjects:   {train_subjects}\")\n    print(f\"  Validation subjects: {val_subjects}\")\n    print(f\"  Runs per subject:    {runs}\")\n    print(f\"  Event keys:          {event_keys}\")\n\n    data_dir = Path(\"./eegmmidb\") / \"physionet\"\n    # data_dir = get_project_root() / \"data\" / \"raw\" / \"physionet\"\n    dataset = PhysioNetDataset(str(data_dir))\n\n    preprocess_config = config[\"preprocessing\"]\n    channels = preprocess_config[\"channels\"]\n    use_all_channels = _is_all_channels(channels)\n    original_fs = preprocess_config[\"sampling_rate\"]\n    target_fs = preprocess_config.get(\"target_sampling_rate\", original_fs)\n\n    label_cfg = config[\"labels\"]\n    event_to_class = label_cfg[\"event_to_class\"]\n\n    channel_names: list[str] | None = None\n\n    def load_subjects(subject_ids, label):\n        nonlocal channel_names\n        print(f\"\\n{'='*60}\")\n        print(f\"LOADING {label.upper()} SUBJECTS\")\n        print(\"=\" * 60)\n        all_X, all_y = [], []\n\n        for subject_id in tqdm(subject_ids, desc=f\"{label} subjects\"):\n            try:\n                dataset.download_subject(subject_id, runs)\n                X, y, event_id, subject_channel_names = dataset.load_subject(\n                    subject_id,\n                    runs,\n                    channels,\n                    event_keys=event_keys,\n                    return_event_id=True,\n                    return_channel_names=True,\n                )\n\n                if X is None or len(X) == 0:\n                    print(f\"  Subject {subject_id}: no data, skipping\")\n                    continue\n\n                if channel_names is None:\n                    channel_names = subject_channel_names\n                    mode = \"all\" if use_all_channels else \"subset\"\n                    print(f\"  Channel mode: {mode} ({len(channel_names)} channels)\")\n                elif subject_channel_names != channel_names:\n                    print(f\"  Subject {subject_id}: channel mismatch, skipping\")\n                    continue\n\n                label_map = {}\n                for event_key, class_id in event_to_class.items():\n                    if event_key not in event_id:\n                        continue\n                    label_map[event_id[event_key]] = class_id\n\n                if len(label_map) < 3:\n                    print(f\"  Subject {subject_id}: missing events, skipping\")\n                    continue\n\n                y = np.array([label_map[v] for v in y])\n\n                X = preprocess_eeg(\n                    X,\n                    lowcut=preprocess_config[\"lowcut\"],\n                    highcut=preprocess_config[\"highcut\"],\n                    fs=original_fs,\n                )\n                X = _resample_epochs(X, original_fs, target_fs)\n\n                all_X.append(X)\n                all_y.append(y)\n                print(f\"  Subject {subject_id}: OK {len(X)} epochs\")\n\n            except Exception as e:\n                print(f\"  Subject {subject_id}: ERROR {e}\")\n\n        return all_X, all_y\n\n    train_X, train_y = load_subjects(train_subjects, \"training\")\n    val_X, val_y = load_subjects(val_subjects, \"validation\")\n\n    if not train_X or not val_X or channel_names is None:\n        print(\"train_X\", not not train_X)\n        print(\"val_X\", not not val_X)\n        print(\"channel_names\", not not channel_names)\n        print(\"\\nNeed data for both training and validation.\")\n        return None, None, None, None, None\n\n    X_train = np.concatenate(train_X)\n    y_train = np.concatenate(train_y)\n    X_val = np.concatenate(val_X)\n    y_val = np.concatenate(val_y)\n\n    print(f\"\\n{'='*60}\")\n    print(\"DATASET SUMMARY\")\n    print(\"=\" * 60)\n    print(f\"  Train: {len(X_train)} epochs {X_train.shape}  classes={np.bincount(y_train)}\")\n    print(f\"  Val:   {len(X_val)} epochs {X_val.shape}  classes={np.bincount(y_val)}\")\n    print(f\"  Channels used: {len(channel_names)}\")\n    print(f\"  Labels: {label_cfg['class_names']}\")\n\n    return X_train, y_train, X_val, y_val, channel_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:15:45.215186Z","iopub.execute_input":"2026-02-28T07:15:45.215409Z","iopub.status.idle":"2026-02-28T07:15:45.336970Z","shell.execute_reply.started":"2026-02-28T07:15:45.215387Z","shell.execute_reply":"2026-02-28T07:15:45.336254Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"config = load_config(\"labram_probe\")\n\nX_train, y_train, X_val, y_val, channel_names = prepare_data(config)\nif X_train is None:\n    print(\"Cannot proceed without data. Exiting.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:15:45.338041Z","iopub.execute_input":"2026-02-28T07:15:45.338430Z","iopub.status.idle":"2026-02-28T07:18:49.456469Z","shell.execute_reply.started":"2026-02-28T07:15:45.338404Z","shell.execute_reply":"2026-02-28T07:18:49.455576Z"}},"outputs":[{"name":"stdout","text":"============================================================\nPREPARING DATASET (LaBraM Probe)\n============================================================\n\n  Training subjects:   [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n  Validation subjects: [41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n  Runs per subject:    [4, 8, 12]\n  Event keys:          ['T0', 'T1', 'T2']\n\n============================================================\nLOADING TRAINING SUBJECTS\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"training subjects:   0%|          | 0/39 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Downloading subject 001...\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Do you want to set the path:\n    /kaggle/working/eegmmidb\nas the default EEGBCI dataset path in the mne-python config [y]/n?  y\n"},{"name":"stdout","text":"Attempting to create new mne-python configuration file:\n/root/.mne/mne-python.json\nCould not read the /root/.mne/mne-python.json json file during the writing. Assuming it is empty. Got: Expecting value: line 1 column 1 (char 0)\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n  Channel mode: all (64 channels)\n","output_type":"stream"},{"name":"stderr","text":"training subjects:   3%|▎         | 1/39 [01:46<1:07:30, 106.58s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 1: OK 90 epochs\nDownloading subject 002...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:   5%|▌         | 2/39 [01:48<27:39, 44.86s/it]   ","output_type":"stream"},{"name":"stdout","text":"  Subject 2: OK 90 epochs\nDownloading subject 003...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:   8%|▊         | 3/39 [01:49<15:03, 25.10s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 3: OK 90 epochs\nDownloading subject 004...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  10%|█         | 4/39 [01:51<09:13, 15.82s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 4: OK 90 epochs\nDownloading subject 006...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  13%|█▎        | 5/39 [01:53<06:03, 10.70s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 6: OK 90 epochs\nDownloading subject 007...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  15%|█▌        | 6/39 [01:54<04:10,  7.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 7: OK 90 epochs\nDownloading subject 008...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  18%|█▊        | 7/39 [01:56<03:00,  5.64s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 8: OK 90 epochs\nDownloading subject 009...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  21%|██        | 8/39 [01:57<02:15,  4.37s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 9: OK 90 epochs\nDownloading subject 010...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  23%|██▎       | 9/39 [01:59<01:45,  3.50s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 10: OK 90 epochs\nDownloading subject 011...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  26%|██▌       | 10/39 [02:01<01:24,  2.92s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 11: OK 90 epochs\nDownloading subject 012...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  28%|██▊       | 11/39 [02:02<01:10,  2.52s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 12: OK 90 epochs\nDownloading subject 013...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  31%|███       | 12/39 [02:04<01:00,  2.24s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 13: OK 90 epochs\nDownloading subject 014...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  33%|███▎      | 13/39 [02:05<00:53,  2.04s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 14: OK 90 epochs\nDownloading subject 015...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  36%|███▌      | 14/39 [02:07<00:47,  1.91s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 15: OK 90 epochs\nDownloading subject 016...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  38%|███▊      | 15/39 [02:09<00:43,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 16: OK 90 epochs\nDownloading subject 017...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  41%|████      | 16/39 [02:10<00:40,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 17: OK 90 epochs\nDownloading subject 018...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  44%|████▎     | 17/39 [02:12<00:37,  1.72s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 18: OK 90 epochs\nDownloading subject 019...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  46%|████▌     | 18/39 [02:13<00:35,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 19: OK 90 epochs\nDownloading subject 020...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  49%|████▊     | 19/39 [02:15<00:33,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 20: OK 90 epochs\nDownloading subject 021...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  51%|█████▏    | 20/39 [02:17<00:30,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 21: OK 90 epochs\nDownloading subject 022...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  54%|█████▍    | 21/39 [02:18<00:29,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 22: OK 90 epochs\nDownloading subject 023...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  56%|█████▋    | 22/39 [02:20<00:28,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 23: OK 90 epochs\nDownloading subject 024...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  59%|█████▉    | 23/39 [02:22<00:26,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 24: OK 90 epochs\nDownloading subject 025...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  62%|██████▏   | 24/39 [02:23<00:24,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 25: OK 90 epochs\nDownloading subject 026...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  64%|██████▍   | 25/39 [02:25<00:22,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 26: OK 90 epochs\nDownloading subject 027...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  67%|██████▋   | 26/39 [02:26<00:20,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 27: OK 90 epochs\nDownloading subject 028...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  69%|██████▉   | 27/39 [02:28<00:19,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 28: OK 90 epochs\nDownloading subject 029...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  72%|███████▏  | 28/39 [02:30<00:17,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 29: OK 90 epochs\nDownloading subject 030...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  74%|███████▍  | 29/39 [02:31<00:16,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 30: OK 90 epochs\nDownloading subject 031...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  77%|███████▋  | 30/39 [02:33<00:14,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 31: OK 90 epochs\nDownloading subject 032...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  79%|███████▉  | 31/39 [02:34<00:12,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 32: OK 90 epochs\nDownloading subject 033...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  82%|████████▏ | 32/39 [02:36<00:11,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 33: OK 90 epochs\nDownloading subject 034...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  85%|████████▍ | 33/39 [02:38<00:09,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 34: OK 90 epochs\nDownloading subject 035...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  87%|████████▋ | 34/39 [02:39<00:08,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 35: OK 90 epochs\nDownloading subject 036...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  90%|████████▉ | 35/39 [02:41<00:06,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 36: OK 90 epochs\nDownloading subject 037...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  92%|█████████▏| 36/39 [02:42<00:04,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 37: OK 90 epochs\nDownloading subject 038...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  95%|█████████▍| 37/39 [02:44<00:03,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 38: OK 90 epochs\nDownloading subject 039...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects:  97%|█████████▋| 38/39 [02:46<00:01,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 39: OK 90 epochs\nDownloading subject 040...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"training subjects: 100%|██████████| 39/39 [02:47<00:00,  4.30s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Subject 40: OK 90 epochs\n\n============================================================\nLOADING VALIDATION SUBJECTS\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Downloading subject 041...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  10%|█         | 1/10 [00:01<00:14,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 41: OK 90 epochs\nDownloading subject 042...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  20%|██        | 2/10 [00:03<00:12,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 42: OK 90 epochs\nDownloading subject 043...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  30%|███       | 3/10 [00:04<00:11,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 43: OK 90 epochs\nDownloading subject 044...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  40%|████      | 4/10 [00:06<00:09,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 44: OK 90 epochs\nDownloading subject 045...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  50%|█████     | 5/10 [00:07<00:07,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 45: OK 90 epochs\nDownloading subject 046...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  60%|██████    | 6/10 [00:09<00:06,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 46: OK 90 epochs\nDownloading subject 047...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  70%|███████   | 7/10 [00:11<00:04,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 47: OK 90 epochs\nDownloading subject 048...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  80%|████████  | 8/10 [00:12<00:03,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 48: OK 90 epochs\nDownloading subject 049...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects:  90%|█████████ | 9/10 [00:14<00:01,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 49: OK 90 epochs\nDownloading subject 050...\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n  Available events: {np.str_('T0'): 1, np.str_('T1'): 2, np.str_('T2'): 3}\n","output_type":"stream"},{"name":"stderr","text":"validation subjects: 100%|██████████| 10/10 [00:15<00:00,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"  Subject 50: OK 90 epochs\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nDATASET SUMMARY\n============================================================\n  Train: 3510 epochs (3510, 64, 601)  classes=[ 884  871 1755]\n  Val:   900 epochs (900, 64, 601)  classes=[229 221 450]\n  Channels used: 64\n  Labels: {0: 'left', 1: 'right', 2: 'rest'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"np.bincount(y_train), np.bincount(y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:18:49.457641Z","iopub.execute_input":"2026-02-28T07:18:49.457976Z","iopub.status.idle":"2026-02-28T07:18:49.465275Z","shell.execute_reply.started":"2026-02-28T07:18:49.457941Z","shell.execute_reply":"2026-02-28T07:18:49.464676Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(array([ 884,  871, 1755]), array([229, 221, 450]))"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        if self.pooling == \"cls\":\n            raise ValueError(\"CLS pooling is handled in forward() using class token.\")\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def encode(self, x: torch.Tensor, force_no_grad: bool = False) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            def _encode_inner():\n                if self.pooling == \"cls\":\n                    # (B, N*P+1, E); index 0 is class token\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    return tokens_all[:, 0, :]\n\n                patch_tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n                return self._pool_tokens(patch_tokens)\n\n            if force_no_grad:\n                with torch.no_grad():\n                    pooled = _encode_inner()\n            else:\n                pooled = _encode_inner()\n        else:\n            with torch.no_grad():\n                if self.pooling == \"cls\":\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    pooled = tokens_all[:, 0, :]\n                else:\n                    patch_tokens = self.encoder(\n                        x, channel_names=self.channel_names, return_patch_tokens=True\n                    )\n                    pooled = self._pool_tokens(patch_tokens)\n\n        return pooled\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        pooled = self.encode(x)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nuse_binary_t1_t2 = True\nuse_long_context_resample = True\ntarget_context_len = 1600\n\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\nX_val = np.asarray(X_val)\ny_val = np.asarray(y_val)\n\nif use_binary_t1_t2:\n    # Keep only T1/T2 classes (commonly encoded as 0/1 in this pipeline).\n    # If upstream encoding differs, remap the two retained class ids to {0, 1}.\n    candidate_labels = [0, 1]\n    train_mask = np.isin(y_train, candidate_labels)\n    val_mask = np.isin(y_val, candidate_labels)\n\n    X_train = X_train[train_mask]\n    y_train = y_train[train_mask]\n    X_val = X_val[val_mask]\n    y_val = y_val[val_mask]\n\n    kept_labels = sorted(set(y_train.tolist()) | set(y_val.tolist()))\n    label_remap = {old: new for new, old in enumerate(kept_labels)}\n    y_train = np.array([label_remap[int(v)] for v in y_train], dtype=np.int64)\n    y_val = np.array([label_remap[int(v)] for v in y_val], dtype=np.int64)\n\n    num_classes = 2\n    print(\n        f\"  Binary mode enabled (T1/T2 only). \"\n        f\"Kept labels={kept_labels}, remap={label_remap}\"\n    )\nelse:\n    num_classes = int(config[\"model\"][\"num_classes\"])\n\ndef resample_epochs_to_length(X: np.ndarray, target_len: int) -> np.ndarray:\n    # Resample each epoch/channel to fixed temporal length expected by LaBraM context.\n    if X.shape[-1] == target_len:\n        return X\n    n_epochs, n_channels, src_len = X.shape\n    x_old = np.linspace(0.0, 1.0, src_len, dtype=np.float32)\n    x_new = np.linspace(0.0, 1.0, target_len, dtype=np.float32)\n    X_out = np.empty((n_epochs, n_channels, target_len), dtype=np.float32)\n    for i in range(n_epochs):\n        for ch in range(n_channels):\n            X_out[i, ch] = np.interp(x_new, x_old, X[i, ch].astype(np.float32))\n    return X_out\n\ndef zscore_epochs(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n    # Per-epoch, per-channel normalization over time.\n    mu = X.mean(axis=-1, keepdims=True)\n    sd = X.std(axis=-1, keepdims=True)\n    return (X - mu) / (sd + eps)\n\nif use_long_context_resample:\n    X_train = resample_epochs_to_length(X_train, target_context_len)\n    X_val = resample_epochs_to_length(X_val, target_context_len)\n    print(\n        f\"  Long-context resample enabled. \"\n        f\"New sequence length={target_context_len}\"\n    )\n\nX_train = zscore_epochs(X_train)\nX_val = zscore_epochs(X_val)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = False\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\npooling_mode = \"cls\"\nfull_finetune = True\nunfreeze_last_n_blocks = 0\nhead_lr = 2e-4\nencoder_lr = 2e-5\nweight_decay = 1e-4\nlabel_smoothing = 0.05\nmax_grad_norm = 1.0\nwarmup_ratio = 0.1\nprint(\n    f\"  Overrides | pooling={pooling_mode} \"\n    f\"full_finetune={full_finetune} \"\n    f\"unfreeze_last_n_blocks={unfreeze_last_n_blocks} \"\n    f\"head_lr={head_lr} encoder_lr={encoder_lr} \"\n    f\"label_smoothing={label_smoothing}\"\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=num_classes,\n    freeze_encoder=not full_finetune,\n    unfreeze_last_n_blocks=unfreeze_last_n_blocks,\n    pooling=pooling_mode,\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ndef run_linear_probe_sanity(\n    model: LaBraMProbe,\n    X_train_t: torch.Tensor,\n    y_train_t: torch.Tensor,\n    X_val_t: torch.Tensor,\n    y_val_t: torch.Tensor,\n    num_classes: int,\n    device: str,\n    batch_size: int = 256,\n    epochs: int = 25,\n    lr: float = 1e-2,\n):\n    print(\"\\n[Sanity] Running frozen-embedding linear probe...\")\n\n    def extract_features(X_tensor: torch.Tensor) -> torch.Tensor:\n        feat_loader = DataLoader(\n            TensorDataset(X_tensor), batch_size=batch_size, shuffle=False\n        )\n        features = []\n        model.eval()\n        with torch.no_grad():\n            for (x_batch,) in feat_loader:\n                x_batch = x_batch.to(device)\n                pooled = model.encode(x_batch, force_no_grad=True)\n                features.append(pooled.cpu())\n        return torch.cat(features, dim=0)\n\n    train_features = extract_features(X_train_t)\n    val_features = extract_features(X_val_t)\n    print(\n        f\"[Sanity] Feature shapes train={tuple(train_features.shape)} \"\n        f\"val={tuple(val_features.shape)}\"\n    )\n\n    linear_head = nn.Linear(train_features.shape[1], num_classes).to(device)\n    sanity_optimizer = optim.AdamW(linear_head.parameters(), lr=lr)\n    sanity_criterion = nn.CrossEntropyLoss()\n\n    sanity_train_loader = DataLoader(\n        TensorDataset(train_features, y_train_t), batch_size=batch_size, shuffle=True\n    )\n    sanity_val_loader = DataLoader(\n        TensorDataset(val_features, y_val_t), batch_size=batch_size, shuffle=False\n    )\n\n    best_val_acc = 0.0\n    for ep in range(1, epochs + 1):\n        linear_head.train()\n        train_correct = 0\n        train_total = 0\n        train_losses = []\n        for feat_batch, y_batch in sanity_train_loader:\n            feat_batch = feat_batch.to(device)\n            y_batch = y_batch.to(device)\n            sanity_optimizer.zero_grad()\n            logits = linear_head(feat_batch)\n            loss = sanity_criterion(logits, y_batch)\n            loss.backward()\n            sanity_optimizer.step()\n\n            preds = logits.argmax(1)\n            train_correct += (preds == y_batch).sum().item()\n            train_total += y_batch.numel()\n            train_losses.append(loss.item())\n\n        linear_head.eval()\n        val_correct = 0\n        val_total = 0\n        all_val_preds = []\n        all_val_targets = []\n        with torch.no_grad():\n            for feat_batch, y_batch in sanity_val_loader:\n                feat_batch = feat_batch.to(device)\n                y_batch = y_batch.to(device)\n                logits = linear_head(feat_batch)\n                preds = logits.argmax(1)\n                val_correct += (preds == y_batch).sum().item()\n                val_total += y_batch.numel()\n                all_val_preds.append(preds.cpu())\n                all_val_targets.append(y_batch.cpu())\n\n        train_acc = train_correct / max(train_total, 1)\n        val_acc = val_correct / max(val_total, 1)\n        best_val_acc = max(best_val_acc, val_acc)\n\n        if ep == 1 or ep % 5 == 0 or ep == epochs:\n            val_preds_flat = torch.cat(all_val_preds)\n            val_targets_flat = torch.cat(all_val_targets)\n            val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n            val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n            print(\n                f\"[Sanity] Epoch {ep:02d}/{epochs} \"\n                f\"train_loss={np.mean(train_losses):.4f} \"\n                f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n            )\n            print(\n                f\"[Sanity] Val true counts={val_true_counts.tolist()} \"\n                f\"pred counts={val_pred_counts.tolist()}\"\n            )\n\n    print(f\"[Sanity] Best val acc: {best_val_acc:.4f}\\n\")\n\n\nrun_linear_sanity_check = True\nif run_linear_sanity_check:\n    run_linear_probe_sanity(\n        model=model,\n        X_train_t=X_train_t,\n        y_train_t=y_train_t,\n        X_val_t=X_val_t,\n        y_val_t=y_val_t,\n        num_classes=num_classes,\n        device=device,\n        batch_size=batch_size,\n        epochs=25,\n        lr=1e-2,\n    )\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(\n        weight=ce_weights, label_smoothing=label_smoothing\n    )\nelse:\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model.unfreeze_last_n_blocks})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\nuse_amp = device == \"cuda\"\namp_dtype = torch.float16 if use_amp else None\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\nprint(f\"  AMP enabled={use_amp}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nsteps_per_epoch = max(1, len(train_loader))\ntotal_steps = max(1, num_epochs * steps_per_epoch)\nwarmup_steps = int(total_steps * warmup_ratio)\n\ndef lr_lambda(current_step: int) -> float:\n    if warmup_steps > 0 and current_step < warmup_steps:\n        return float(current_step + 1) / float(warmup_steps)\n    progress = (current_step - warmup_steps) / max(1, total_steps - warmup_steps)\n    progress = min(max(progress, 0.0), 1.0)\n    return 0.5 * (1.0 + np.cos(np.pi * progress))\n\nscheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\nprint(\n    f\"  Scheduler | total_steps={total_steps} \"\n    f\"warmup_steps={warmup_steps} warmup_ratio={warmup_ratio}\"\n)\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n                logits = model(X_batch)\n                loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    current_lrs = [pg[\"lr\"] for pg in optimizer.param_groups]\n    print(f\"  LRs={current_lrs}\")\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:18:49.466145Z","iopub.execute_input":"2026-02-28T07:18:49.466413Z","iopub.status.idle":"2026-02-28T07:41:16.899992Z","shell.execute_reply.started":"2026-02-28T07:18:49.466379Z","shell.execute_reply":"2026-02-28T07:41:16.899342Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Binary mode enabled (T1/T2 only). Kept labels=[0, 1], remap={0: 0, 1: 1}\n  Long-context resample enabled. New sequence length=1600\n  Train class counts: [884.0, 871.0]\n  Val class counts:   [229.0, 221.0]\n  Overrides | pooling=cls full_finetune=True unfreeze_last_n_blocks=0 head_lr=0.0002 encoder_lr=2e-05 label_smoothing=0.05\n\n  Device: cuda\n\n[Sanity] Running frozen-embedding linear probe...\n[Sanity] Feature shapes train=(1755, 200) val=(450, 200)\n[Sanity] Epoch 01/25 train_loss=1.0443 train_acc=0.4946 val_acc=0.5311\n[Sanity] Val true counts=[229, 221] pred counts=[218, 232]\n[Sanity] Epoch 05/25 train_loss=0.7882 train_acc=0.5088 val_acc=0.4911\n[Sanity] Val true counts=[229, 221] pred counts=[0, 450]\n[Sanity] Epoch 10/25 train_loss=1.0632 train_acc=0.4974 val_acc=0.4911\n[Sanity] Val true counts=[229, 221] pred counts=[0, 450]\n[Sanity] Epoch 15/25 train_loss=0.7632 train_acc=0.5151 val_acc=0.4933\n[Sanity] Val true counts=[229, 221] pred counts=[1, 449]\n[Sanity] Epoch 20/25 train_loss=0.7634 train_acc=0.5179 val_acc=0.4911\n[Sanity] Val true counts=[229, 221] pred counts=[0, 450]\n[Sanity] Epoch 25/25 train_loss=0.7068 train_acc=0.5345 val_acc=0.5000\n[Sanity] Val true counts=[229, 221] pred counts=[34, 416]\n[Sanity] Best val acc: 0.5444\n\n  Trainable params | head=51,970 encoder=7,471,528 (unfreeze_last_n_blocks=0)\n  Optimizer LRs | head=0.0002 encoder=2e-05 weight_decay=0.0001\n  AMP enabled=True\n  Scheduler | total_steps=11000 warmup_steps=1100 warmup_ratio=0.1\n  Epochs: 200  |  Early-stop patience: 40\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/2759695412.py:418: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n/tmp/ipykernel_55/2759695412.py:466: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/tmp/ipykernel_55/2759695412.py:492: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 001/200 | Train loss=0.9566 acc=0.4946 | Val loss=0.7032 acc=0.5089\n  LRs=[1.0181818181818182e-05, 1.0181818181818183e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  New best (0.5089) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=0.8094 acc=0.5174 | Val loss=0.6925 acc=0.4933\n  LRs=[2.0181818181818183e-05, 2.0181818181818185e-06]\n  Val true counts=[229, 221] pred counts=[47, 403]\n  Val per-class acc=[0.10480349510908127, 0.8959276080131531]\nEpoch 003/200 | Train loss=0.8110 acc=0.4952 | Val loss=0.6959 acc=0.4911\n  LRs=[3.0181818181818182e-05, 3.0181818181818182e-06]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\nEpoch 004/200 | Train loss=0.7868 acc=0.5145 | Val loss=0.6916 acc=0.5111\n  LRs=[4.018181818181818e-05, 4.018181818181818e-06]\n  Val true counts=[229, 221] pred counts=[157, 293]\n  Val per-class acc=[0.3624454140663147, 0.6651583909988403]\n  New best (0.5111) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 005/200 | Train loss=0.7765 acc=0.4792 | Val loss=0.6952 acc=0.5089\n  LRs=[5.018181818181819e-05, 5.0181818181818186e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 006/200 | Train loss=0.7450 acc=0.5197 | Val loss=0.6915 acc=0.5222\n  LRs=[6.0181818181818187e-05, 6.018181818181818e-06]\n  Val true counts=[229, 221] pred counts=[286, 164]\n  Val per-class acc=[0.6550218462944031, 0.38461539149284363]\n  New best (0.5222) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 007/200 | Train loss=0.7279 acc=0.5020 | Val loss=0.7134 acc=0.4911\n  LRs=[7.018181818181818e-05, 7.018181818181818e-06]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\nEpoch 008/200 | Train loss=0.7202 acc=0.4917 | Val loss=0.6977 acc=0.5089\n  LRs=[8.018181818181818e-05, 8.018181818181818e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 009/200 | Train loss=0.7129 acc=0.5288 | Val loss=0.6914 acc=0.5133\n  LRs=[9.018181818181819e-05, 9.01818181818182e-06]\n  Val true counts=[229, 221] pred counts=[350, 100]\n  Val per-class acc=[0.7860261797904968, 0.23076923191547394]\nEpoch 010/200 | Train loss=0.7068 acc=0.5037 | Val loss=0.6950 acc=0.5067\n  LRs=[0.00010018181818181818, 1.0018181818181817e-05]\n  Val true counts=[229, 221] pred counts=[447, 3]\n  Val per-class acc=[0.9912663698196411, 0.004524887073785067]\nEpoch 011/200 | Train loss=0.7101 acc=0.4923 | Val loss=0.6907 acc=0.5089\n  LRs=[0.00011018181818181819, 1.101818181818182e-05]\n  Val true counts=[229, 221] pred counts=[398, 52]\n  Val per-class acc=[0.8864628672599792, 0.11764705926179886]\nEpoch 012/200 | Train loss=0.6997 acc=0.5077 | Val loss=0.6922 acc=0.5178\n  LRs=[0.0001201818181818182, 1.201818181818182e-05]\n  Val true counts=[229, 221] pred counts=[202, 248]\n  Val per-class acc=[0.46724891662597656, 0.570135772228241]\nEpoch 013/200 | Train loss=0.6967 acc=0.5197 | Val loss=0.6982 acc=0.5089\n  LRs=[0.0001301818181818182, 1.3018181818181819e-05]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 014/200 | Train loss=0.6981 acc=0.5202 | Val loss=0.6999 acc=0.4911\n  LRs=[0.00014018181818181819, 1.401818181818182e-05]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\nEpoch 015/200 | Train loss=0.6927 acc=0.5271 | Val loss=0.6917 acc=0.4978\n  LRs=[0.00015018181818181819, 1.5018181818181819e-05]\n  Val true counts=[229, 221] pred counts=[345, 105]\n  Val per-class acc=[0.7598253488540649, 0.22624434530735016]\nEpoch 016/200 | Train loss=0.6930 acc=0.5373 | Val loss=0.6955 acc=0.4978\n  LRs=[0.00016018181818181818, 1.601818181818182e-05]\n  Val true counts=[229, 221] pred counts=[21, 429]\n  Val per-class acc=[0.052401747554540634, 0.959276020526886]\nEpoch 017/200 | Train loss=0.6873 acc=0.5487 | Val loss=0.6938 acc=0.4956\n  LRs=[0.0001701818181818182, 1.701818181818182e-05]\n  Val true counts=[229, 221] pred counts=[100, 350]\n  Val per-class acc=[0.22270742058753967, 0.7782805562019348]\nEpoch 018/200 | Train loss=0.6828 acc=0.5607 | Val loss=0.6948 acc=0.4844\n  LRs=[0.00018018181818181818, 1.801818181818182e-05]\n  Val true counts=[229, 221] pred counts=[83, 367]\n  Val per-class acc=[0.17467248439788818, 0.8054298758506775]\nEpoch 019/200 | Train loss=0.6728 acc=0.5932 | Val loss=0.6996 acc=0.4778\n  LRs=[0.00019018181818181818, 1.901818181818182e-05]\n  Val true counts=[229, 221] pred counts=[70, 380]\n  Val per-class acc=[0.13973799347877502, 0.8280543088912964]\nEpoch 020/200 | Train loss=0.6553 acc=0.6245 | Val loss=0.6990 acc=0.4933\n  LRs=[np.float64(0.0002), np.float64(2e-05)]\n  Val true counts=[229, 221] pred counts=[163, 287]\n  Val per-class acc=[0.35807859897613525, 0.6334841847419739]\nEpoch 021/200 | Train loss=0.6328 acc=0.6718 | Val loss=0.7129 acc=0.4822\n  LRs=[np.float64(0.00019998476951563915), np.float64(1.9998476951563914e-05)]\n  Val true counts=[229, 221] pred counts=[178, 272]\n  Val per-class acc=[0.37991267442703247, 0.5882353186607361]\nEpoch 022/200 | Train loss=0.6113 acc=0.6815 | Val loss=0.7298 acc=0.4867\n  LRs=[np.float64(0.0001999390827019096), np.float64(1.999390827019096e-05)]\n  Val true counts=[229, 221] pred counts=[128, 322]\n  Val per-class acc=[0.2751091718673706, 0.7058823704719543]\nEpoch 023/200 | Train loss=0.5799 acc=0.7185 | Val loss=0.7372 acc=0.4711\n  LRs=[np.float64(0.0001998629534754574), np.float64(1.9986295347545738e-05)]\n  Val true counts=[229, 221] pred counts=[261, 189]\n  Val per-class acc=[0.5502183437347412, 0.3891402781009674]\nEpoch 024/200 | Train loss=0.5566 acc=0.7390 | Val loss=0.7538 acc=0.4822\n  LRs=[np.float64(0.00019975640502598244), np.float64(1.9975640502598243e-05)]\n  Val true counts=[229, 221] pred counts=[246, 204]\n  Val per-class acc=[0.528384268283844, 0.4343891441822052]\nEpoch 025/200 | Train loss=0.5314 acc=0.7550 | Val loss=0.8046 acc=0.4778\n  LRs=[np.float64(0.00019961946980917456), np.float64(1.9961946980917457e-05)]\n  Val true counts=[229, 221] pred counts=[308, 142]\n  Val per-class acc=[0.6593886613845825, 0.28959277272224426]\nEpoch 026/200 | Train loss=0.4872 acc=0.7966 | Val loss=0.8389 acc=0.4756\n  LRs=[np.float64(0.00019945218953682734), np.float64(1.9945218953682736e-05)]\n  Val true counts=[229, 221] pred counts=[267, 183]\n  Val per-class acc=[0.567685604095459, 0.38009050488471985]\nEpoch 027/200 | Train loss=0.4443 acc=0.8422 | Val loss=0.8747 acc=0.4689\n  LRs=[np.float64(0.00019925461516413223), np.float64(1.9925461516413224e-05)]\n  Val true counts=[229, 221] pred counts=[160, 290]\n  Val per-class acc=[0.32751092314720154, 0.6153846383094788]\nEpoch 028/200 | Train loss=0.4251 acc=0.8319 | Val loss=0.9005 acc=0.4689\n  LRs=[np.float64(0.00019902680687415705), np.float64(1.9902680687415704e-05)]\n  Val true counts=[229, 221] pred counts=[182, 268]\n  Val per-class acc=[0.375545859336853, 0.5656108856201172]\nEpoch 029/200 | Train loss=0.3938 acc=0.8541 | Val loss=1.0180 acc=0.4956\n  LRs=[np.float64(0.00019876883405951377), np.float64(1.9876883405951378e-05)]\n  Val true counts=[229, 221] pred counts=[322, 128]\n  Val per-class acc=[0.7074235677719116, 0.2760181128978729]\nEpoch 030/200 | Train loss=0.3474 acc=0.8855 | Val loss=1.0357 acc=0.4689\n  LRs=[np.float64(0.00019848077530122083), np.float64(1.9848077530122083e-05)]\n  Val true counts=[229, 221] pred counts=[176, 274]\n  Val per-class acc=[0.3624454140663147, 0.5791855454444885]\nEpoch 031/200 | Train loss=0.3222 acc=0.8991 | Val loss=1.1105 acc=0.4733\n  LRs=[np.float64(0.00019816271834476642), np.float64(1.9816271834476642e-05)]\n  Val true counts=[229, 221] pred counts=[264, 186]\n  Val per-class acc=[0.5589519739151001, 0.38461539149284363]\nEpoch 032/200 | Train loss=0.2826 acc=0.9236 | Val loss=1.2021 acc=0.4867\n  LRs=[np.float64(0.00019781476007338058), np.float64(1.9781476007338058e-05)]\n  Val true counts=[229, 221] pred counts=[264, 186]\n  Val per-class acc=[0.5720524191856384, 0.39819005131721497]\nEpoch 033/200 | Train loss=0.2528 acc=0.9373 | Val loss=1.2545 acc=0.4956\n  LRs=[np.float64(0.00019743700647852354), np.float64(1.9743700647852356e-05)]\n  Val true counts=[229, 221] pred counts=[260, 190]\n  Val per-class acc=[0.5720524191856384, 0.4162895977497101]\nEpoch 034/200 | Train loss=0.2193 acc=0.9584 | Val loss=1.3713 acc=0.4867\n  LRs=[np.float64(0.00019702957262759965), np.float64(1.9702957262759964e-05)]\n  Val true counts=[229, 221] pred counts=[212, 238]\n  Val per-class acc=[0.4585152864456177, 0.5158371329307556]\nEpoch 035/200 | Train loss=0.2012 acc=0.9698 | Val loss=1.5081 acc=0.4933\n  LRs=[np.float64(0.00019659258262890683), np.float64(1.9659258262890683e-05)]\n  Val true counts=[229, 221] pred counts=[313, 137]\n  Val per-class acc=[0.6855894923210144, 0.29411765933036804]\nEpoch 036/200 | Train loss=0.1855 acc=0.9761 | Val loss=1.4892 acc=0.4800\n  LRs=[np.float64(0.0001961261695938319), np.float64(1.961261695938319e-05)]\n  Val true counts=[229, 221] pred counts=[245, 205]\n  Val per-class acc=[0.5240174531936646, 0.4343891441822052]\nEpoch 037/200 | Train loss=0.1742 acc=0.9852 | Val loss=1.5983 acc=0.4733\n  LRs=[np.float64(0.00019563047559630357), np.float64(1.9563047559630356e-05)]\n  Val true counts=[229, 221] pred counts=[190, 260]\n  Val per-class acc=[0.39737990498542786, 0.5520362257957458]\nEpoch 038/200 | Train loss=0.1652 acc=0.9858 | Val loss=1.5232 acc=0.4822\n  LRs=[np.float64(0.00019510565162951537), np.float64(1.9510565162951538e-05)]\n  Val true counts=[229, 221] pred counts=[214, 236]\n  Val per-class acc=[0.4585152864456177, 0.5067873597145081]\nEpoch 039/200 | Train loss=0.1594 acc=0.9926 | Val loss=1.5658 acc=0.4644\n  LRs=[np.float64(0.0001945518575599317), np.float64(1.945518575599317e-05)]\n  Val true counts=[229, 221] pred counts=[190, 260]\n  Val per-class acc=[0.38864627480506897, 0.5429864525794983]\nEpoch 040/200 | Train loss=0.1709 acc=0.9823 | Val loss=1.7454 acc=0.4733\n  LRs=[np.float64(0.00019396926207859084), np.float64(1.9396926207859085e-05)]\n  Val true counts=[229, 221] pred counts=[142, 308]\n  Val per-class acc=[0.2925764322280884, 0.6606335043907166]\nEpoch 041/200 | Train loss=0.1639 acc=0.9880 | Val loss=1.6181 acc=0.4689\n  LRs=[np.float64(0.00019335804264972018), np.float64(1.9335804264972018e-05)]\n  Val true counts=[229, 221] pred counts=[218, 232]\n  Val per-class acc=[0.45414847135543823, 0.4841628968715668]\nEpoch 042/200 | Train loss=0.1491 acc=0.9966 | Val loss=1.5990 acc=0.4756\n  LRs=[np.float64(0.00019271838545667876), np.float64(1.9271838545667876e-05)]\n  Val true counts=[229, 221] pred counts=[229, 221]\n  Val per-class acc=[0.48471614718437195, 0.46606335043907166]\nEpoch 043/200 | Train loss=0.1503 acc=0.9932 | Val loss=1.6314 acc=0.5022\n  LRs=[np.float64(0.00019205048534524406), np.float64(1.9205048534524405e-05)]\n  Val true counts=[229, 221] pred counts=[257, 193]\n  Val per-class acc=[0.5720524191856384, 0.4298642575740814]\nEpoch 044/200 | Train loss=0.1473 acc=0.9949 | Val loss=1.5768 acc=0.4889\n  LRs=[np.float64(0.0001913545457642601), np.float64(1.913545457642601e-05)]\n  Val true counts=[229, 221] pred counts=[209, 241]\n  Val per-class acc=[0.45414847135543823, 0.5248869061470032]\nEpoch 045/200 | Train loss=0.1428 acc=0.9977 | Val loss=1.5727 acc=0.5022\n  LRs=[np.float64(0.000190630778703665), np.float64(1.9063077870366504e-05)]\n  Val true counts=[229, 221] pred counts=[263, 187]\n  Val per-class acc=[0.5851528644561768, 0.4162895977497101]\nEpoch 046/200 | Train loss=0.1391 acc=0.9966 | Val loss=1.5694 acc=0.4778\n  LRs=[np.float64(0.0001898794046299167), np.float64(1.8987940462991673e-05)]\n  Val true counts=[229, 221] pred counts=[262, 188]\n  Val per-class acc=[0.5589519739151001, 0.3936651647090912]\n\nEarly stopping at epoch 46.\n\nTraining complete. Best val acc: 0.5222\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = True\n        self.unfreeze_last_n_blocks = 0\n        self.encoder_has_trainable_params = False\n        self.configure_trainable_encoder(\n            freeze_encoder=freeze_encoder,\n            unfreeze_last_n_blocks=unfreeze_last_n_blocks,\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def configure_trainable_encoder(\n        self, freeze_encoder: bool, unfreeze_last_n_blocks: int = 0\n    ) -> None:\n        # Training policy:\n        # - freeze_encoder=True: freeze all encoder weights, then optionally unfreeze last N blocks.\n        # - freeze_encoder=False: full encoder fine-tuning.\n        self.freeze_encoder = bool(freeze_encoder)\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        for param in self.encoder.parameters():\n            param.requires_grad = not self.freeze_encoder\n\n        if self.freeze_encoder and self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        if self.pooling == \"cls\":\n            raise ValueError(\"CLS pooling is handled in forward() using class token.\")\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def encode(self, x: torch.Tensor, force_no_grad: bool = False) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            def _encode_inner():\n                if self.pooling == \"cls\":\n                    # (B, N*P+1, E); index 0 is class token\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    return tokens_all[:, 0, :]\n\n                patch_tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n                return self._pool_tokens(patch_tokens)\n\n            if force_no_grad:\n                with torch.no_grad():\n                    pooled = _encode_inner()\n            else:\n                pooled = _encode_inner()\n        else:\n            with torch.no_grad():\n                if self.pooling == \"cls\":\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    pooled = tokens_all[:, 0, :]\n                else:\n                    patch_tokens = self.encoder(\n                        x, channel_names=self.channel_names, return_patch_tokens=True\n                    )\n                    pooled = self._pool_tokens(patch_tokens)\n\n        return pooled\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        pooled = self.encode(x)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nuse_binary_t1_t2 = True\nuse_long_context_resample = True\ntarget_context_len = 1600\n\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\nX_val = np.asarray(X_val)\ny_val = np.asarray(y_val)\n\nif use_binary_t1_t2:\n    # Keep only T1/T2 classes (commonly encoded as 0/1 in this pipeline).\n    # If upstream encoding differs, remap the two retained class ids to {0, 1}.\n    candidate_labels = [0, 1]\n    train_mask = np.isin(y_train, candidate_labels)\n    val_mask = np.isin(y_val, candidate_labels)\n\n    X_train = X_train[train_mask]\n    y_train = y_train[train_mask]\n    X_val = X_val[val_mask]\n    y_val = y_val[val_mask]\n\n    kept_labels = sorted(set(y_train.tolist()) | set(y_val.tolist()))\n    label_remap = {old: new for new, old in enumerate(kept_labels)}\n    y_train = np.array([label_remap[int(v)] for v in y_train], dtype=np.int64)\n    y_val = np.array([label_remap[int(v)] for v in y_val], dtype=np.int64)\n\n    num_classes = 2\n    print(\n        f\"  Binary mode enabled (T1/T2 only). \"\n        f\"Kept labels={kept_labels}, remap={label_remap}\"\n    )\nelse:\n    num_classes = int(config[\"model\"][\"num_classes\"])\n\ndef resample_epochs_to_length(X: np.ndarray, target_len: int) -> np.ndarray:\n    # Resample each epoch/channel to fixed temporal length expected by LaBraM context.\n    if X.shape[-1] == target_len:\n        return X\n    n_epochs, n_channels, src_len = X.shape\n    x_old = np.linspace(0.0, 1.0, src_len, dtype=np.float32)\n    x_new = np.linspace(0.0, 1.0, target_len, dtype=np.float32)\n    X_out = np.empty((n_epochs, n_channels, target_len), dtype=np.float32)\n    for i in range(n_epochs):\n        for ch in range(n_channels):\n            X_out[i, ch] = np.interp(x_new, x_old, X[i, ch].astype(np.float32))\n    return X_out\n\ndef zscore_epochs(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n    # Per-epoch, per-channel normalization over time.\n    mu = X.mean(axis=-1, keepdims=True)\n    sd = X.std(axis=-1, keepdims=True)\n    return (X - mu) / (sd + eps)\n\nif use_long_context_resample:\n    X_train = resample_epochs_to_length(X_train, target_context_len)\n    X_val = resample_epochs_to_length(X_val, target_context_len)\n    print(\n        f\"  Long-context resample enabled. \"\n        f\"New sequence length={target_context_len}\"\n    )\n\nX_train = zscore_epochs(X_train)\nX_val = zscore_epochs(X_val)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = False\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\npooling_mode = \"cls\"\n# Next run strategy:\n# 1) Stage-1 train head only.\n# 2) Stage-2 unfreeze only last encoder blocks with small LR.\nstage1_head_only_epochs = 12\nstage2_unfreeze_last_n_blocks = 2\nstage1_head_lr = 1e-4\nstage2_head_lr = 5e-5\nstage2_encoder_lr = 5e-6\nweight_decay = 1e-4\nlabel_smoothing = 0.0\nmax_grad_norm = 1.0\nwarmup_ratio = 0.1\nuse_mcc_for_early_stop = True\nprint(\n    f\"  Overrides | pooling={pooling_mode} \"\n    f\"stage1_head_only_epochs={stage1_head_only_epochs} \"\n    f\"stage2_unfreeze_last_n_blocks={stage2_unfreeze_last_n_blocks} \"\n    f\"stage1_head_lr={stage1_head_lr} \"\n    f\"stage2_head_lr={stage2_head_lr} \"\n    f\"stage2_encoder_lr={stage2_encoder_lr} \"\n    f\"label_smoothing={label_smoothing} \"\n    f\"use_mcc_for_early_stop={use_mcc_for_early_stop}\"\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=num_classes,\n    freeze_encoder=True,\n    unfreeze_last_n_blocks=0,\n    pooling=pooling_mode,\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ndef run_linear_probe_sanity(\n    model: LaBraMProbe,\n    X_train_t: torch.Tensor,\n    y_train_t: torch.Tensor,\n    X_val_t: torch.Tensor,\n    y_val_t: torch.Tensor,\n    num_classes: int,\n    device: str,\n    batch_size: int = 256,\n    epochs: int = 25,\n    lr: float = 1e-2,\n):\n    print(\"\\n[Sanity] Running frozen-embedding linear probe...\")\n\n    def extract_features(X_tensor: torch.Tensor) -> torch.Tensor:\n        feat_loader = DataLoader(\n            TensorDataset(X_tensor), batch_size=batch_size, shuffle=False\n        )\n        features = []\n        model.eval()\n        with torch.no_grad():\n            for (x_batch,) in feat_loader:\n                x_batch = x_batch.to(device)\n                pooled = model.encode(x_batch, force_no_grad=True)\n                features.append(pooled.cpu())\n        return torch.cat(features, dim=0)\n\n    train_features = extract_features(X_train_t)\n    val_features = extract_features(X_val_t)\n    print(\n        f\"[Sanity] Feature shapes train={tuple(train_features.shape)} \"\n        f\"val={tuple(val_features.shape)}\"\n    )\n\n    linear_head = nn.Linear(train_features.shape[1], num_classes).to(device)\n    sanity_optimizer = optim.AdamW(linear_head.parameters(), lr=lr)\n    sanity_criterion = nn.CrossEntropyLoss()\n\n    sanity_train_loader = DataLoader(\n        TensorDataset(train_features, y_train_t), batch_size=batch_size, shuffle=True\n    )\n    sanity_val_loader = DataLoader(\n        TensorDataset(val_features, y_val_t), batch_size=batch_size, shuffle=False\n    )\n\n    best_val_acc = 0.0\n    for ep in range(1, epochs + 1):\n        linear_head.train()\n        train_correct = 0\n        train_total = 0\n        train_losses = []\n        for feat_batch, y_batch in sanity_train_loader:\n            feat_batch = feat_batch.to(device)\n            y_batch = y_batch.to(device)\n            sanity_optimizer.zero_grad()\n            logits = linear_head(feat_batch)\n            loss = sanity_criterion(logits, y_batch)\n            loss.backward()\n            sanity_optimizer.step()\n\n            preds = logits.argmax(1)\n            train_correct += (preds == y_batch).sum().item()\n            train_total += y_batch.numel()\n            train_losses.append(loss.item())\n\n        linear_head.eval()\n        val_correct = 0\n        val_total = 0\n        all_val_preds = []\n        all_val_targets = []\n        with torch.no_grad():\n            for feat_batch, y_batch in sanity_val_loader:\n                feat_batch = feat_batch.to(device)\n                y_batch = y_batch.to(device)\n                logits = linear_head(feat_batch)\n                preds = logits.argmax(1)\n                val_correct += (preds == y_batch).sum().item()\n                val_total += y_batch.numel()\n                all_val_preds.append(preds.cpu())\n                all_val_targets.append(y_batch.cpu())\n\n        train_acc = train_correct / max(train_total, 1)\n        val_acc = val_correct / max(val_total, 1)\n        best_val_acc = max(best_val_acc, val_acc)\n\n        if ep == 1 or ep % 5 == 0 or ep == epochs:\n            val_preds_flat = torch.cat(all_val_preds)\n            val_targets_flat = torch.cat(all_val_targets)\n            val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n            val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n            print(\n                f\"[Sanity] Epoch {ep:02d}/{epochs} \"\n                f\"train_loss={np.mean(train_losses):.4f} \"\n                f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n            )\n            print(\n                f\"[Sanity] Val true counts={val_true_counts.tolist()} \"\n                f\"pred counts={val_pred_counts.tolist()}\"\n            )\n\n    print(f\"[Sanity] Best val acc: {best_val_acc:.4f}\\n\")\n\n\nrun_linear_sanity_check = True\nif run_linear_sanity_check:\n    run_linear_probe_sanity(\n        model=model,\n        X_train_t=X_train_t,\n        y_train_t=y_train_t,\n        X_val_t=X_val_t,\n        y_val_t=y_val_t,\n        num_classes=num_classes,\n        device=device,\n        batch_size=batch_size,\n        epochs=25,\n        lr=1e-2,\n    )\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(\n        weight=ce_weights, label_smoothing=label_smoothing\n    )\nelse:\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n\ndef build_optimizer(\n    model: LaBraMProbe, head_lr: float, encoder_lr: float, weight_decay: float\n):\n    head_params = [p for p in model.classifier.parameters() if p.requires_grad]\n    encoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\n\n    if encoder_params:\n        optimizer = optim.AdamW(\n            [\n                {\"params\": head_params, \"lr\": head_lr},\n                {\"params\": encoder_params, \"lr\": encoder_lr},\n            ],\n            weight_decay=weight_decay,\n        )\n    else:\n        optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\n    num_head_params = sum(p.numel() for p in head_params)\n    num_encoder_params = sum(p.numel() for p in encoder_params)\n    return optimizer, num_head_params, num_encoder_params\n\nuse_amp = device == \"cuda\"\namp_dtype = torch.float16 if use_amp else None\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\nprint(f\"  AMP enabled={use_amp}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\nsteps_per_epoch = max(1, len(train_loader))\n\ndef build_scheduler(optimizer, remaining_epochs: int, warmup_ratio: float):\n    total_steps = max(1, remaining_epochs * steps_per_epoch)\n    warmup_steps = int(total_steps * warmup_ratio)\n\n    def lr_lambda(current_step: int) -> float:\n        if warmup_steps > 0 and current_step < warmup_steps:\n            return float(current_step + 1) / float(warmup_steps)\n        progress = (current_step - warmup_steps) / max(1, total_steps - warmup_steps)\n        progress = min(max(progress, 0.0), 1.0)\n        return 0.5 * (1.0 + np.cos(np.pi * progress))\n\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n    return scheduler, total_steps, warmup_steps\n\ndef binary_mcc_from_tensors(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n    tp = int(((y_pred == 1) & (y_true == 1)).sum().item())\n    tn = int(((y_pred == 0) & (y_true == 0)).sum().item())\n    fp = int(((y_pred == 1) & (y_true == 0)).sum().item())\n    fn = int(((y_pred == 0) & (y_true == 1)).sum().item())\n    denom = np.sqrt(float((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n    if denom == 0.0:\n        return 0.0\n    return float((tp * tn - fp * fn) / denom)\n\nselection_metric_name = (\n    \"mcc\" if (num_classes == 2 and use_mcc_for_early_stop) else \"bal_acc\"\n)\nstage2_start_epoch = max(1, int(stage1_head_only_epochs))\nstage2_enabled = stage2_unfreeze_last_n_blocks > 0 and stage2_start_epoch < num_epochs\ncurrent_stage = \"stage1_head_only\"\n\noptimizer, num_head_params, num_encoder_params = build_optimizer(\n    model=model,\n    head_lr=stage1_head_lr,\n    encoder_lr=stage2_encoder_lr,\n    weight_decay=weight_decay,\n)\nscheduler, total_steps, warmup_steps = build_scheduler(\n    optimizer=optimizer,\n    remaining_epochs=num_epochs,\n    warmup_ratio=warmup_ratio,\n)\n\nprint(\n    f\"  Initial stage={current_stage} | \"\n    f\"Trainable params head={num_head_params:,} encoder={num_encoder_params:,}\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={stage1_head_lr} encoder={stage2_encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={stage1_head_lr} weight_decay={weight_decay}\")\nprint(\n    f\"  Scheduler | total_steps={total_steps} \"\n    f\"warmup_steps={warmup_steps} warmup_ratio={warmup_ratio}\"\n)\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nbest_val_acc = 0.0\nbest_val_bal_acc = 0.0\nbest_val_mcc = -1.0 if num_classes == 2 else float(\"nan\")\nbest_selection_metric = -float(\"inf\")\npatience_counter = 0\n\nfor epoch in range(num_epochs):\n    if stage2_enabled and epoch == stage2_start_epoch:\n        model.configure_trainable_encoder(\n            freeze_encoder=True,\n            unfreeze_last_n_blocks=stage2_unfreeze_last_n_blocks,\n        )\n        current_stage = f\"stage2_unfreeze_last_{stage2_unfreeze_last_n_blocks}\"\n        optimizer, num_head_params, num_encoder_params = build_optimizer(\n            model=model,\n            head_lr=stage2_head_lr,\n            encoder_lr=stage2_encoder_lr,\n            weight_decay=weight_decay,\n        )\n        scheduler, total_steps, warmup_steps = build_scheduler(\n            optimizer=optimizer,\n            remaining_epochs=max(1, num_epochs - epoch),\n            warmup_ratio=warmup_ratio,\n        )\n        print(\n            f\"\\n  Stage switch at epoch {epoch+1}: {current_stage} | \"\n            f\"Trainable params head={num_head_params:,} encoder={num_encoder_params:,}\"\n        )\n        print(\n            f\"  Optimizer LRs | head={stage2_head_lr} encoder={stage2_encoder_lr} \"\n            f\"weight_decay={weight_decay}\"\n        )\n        print(\n            f\"  Scheduler reset | total_steps={total_steps} \"\n            f\"warmup_steps={warmup_steps}\\n\"\n        )\n\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n                logits = model(X_batch)\n                loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    current_lrs = [pg[\"lr\"] for pg in optimizer.param_groups]\n    print(f\"  LRs={current_lrs}\")\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    valid_class_acc = [a for a in per_class_acc if not np.isnan(a)]\n    val_bal_acc = float(np.mean(valid_class_acc)) if valid_class_acc else 0.0\n    if num_classes == 2:\n        val_mcc = binary_mcc_from_tensors(val_preds_flat, val_targets_flat)\n        print(f\"  Val bal_acc={val_bal_acc:.4f} val_mcc={val_mcc:.4f}\")\n    else:\n        val_mcc = float(\"nan\")\n        print(f\"  Val bal_acc={val_bal_acc:.4f}\")\n\n    selection_metric = val_mcc if selection_metric_name == \"mcc\" else val_bal_acc\n    print(\n        f\"  Selection metric ({selection_metric_name})={selection_metric:.4f} \"\n        f\"| stage={current_stage}\"\n    )\n\n    if selection_metric > best_selection_metric:\n        best_selection_metric = selection_metric\n        best_val_acc = max(best_val_acc, val_acc)\n        best_val_bal_acc = max(best_val_bal_acc, val_bal_acc)\n        if num_classes == 2:\n            best_val_mcc = max(best_val_mcc, val_mcc)\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"best_val_bal_acc\": best_val_bal_acc,\n                \"best_val_mcc\": best_val_mcc,\n                \"best_selection_metric\": best_selection_metric,\n                \"best_selection_metric_name\": selection_metric_name,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(\n            f\"  New best ({selection_metric_name}={selection_metric:.4f}, \"\n            f\"val_acc={val_acc:.4f}) saved to {save_path}\"\n        )\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(\n    f\"\\nTraining complete. Best {selection_metric_name}: {best_selection_metric:.4f} | \"\n    f\"Best val_acc: {best_val_acc:.4f} | \"\n    f\"Best val_bal_acc: {best_val_bal_acc:.4f}\"\n    + (\n        f\" | Best val_mcc: {best_val_mcc:.4f}\"\n        if num_classes == 2\n        else \"\"\n    )\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T08:06:12.105798Z","iopub.execute_input":"2026-02-28T08:06:12.106299Z","iopub.status.idle":"2026-02-28T08:18:40.071491Z","shell.execute_reply.started":"2026-02-28T08:06:12.106266Z","shell.execute_reply":"2026-02-28T08:18:40.070829Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Binary mode enabled (T1/T2 only). Kept labels=[0, 1], remap={0: 0, 1: 1}\n  Long-context resample enabled. New sequence length=1600\n  Train class counts: [884.0, 871.0]\n  Val class counts:   [229.0, 221.0]\n  Overrides | pooling=cls stage1_head_only_epochs=12 stage2_unfreeze_last_n_blocks=2 stage1_head_lr=0.0001 stage2_head_lr=5e-05 stage2_encoder_lr=5e-06 label_smoothing=0.0 use_mcc_for_early_stop=True\n\n  Device: cuda\n\n[Sanity] Running frozen-embedding linear probe...\n[Sanity] Feature shapes train=(1755, 200) val=(450, 200)\n[Sanity] Epoch 01/25 train_loss=1.0605 train_acc=0.5117 val_acc=0.5044\n[Sanity] Val true counts=[229, 221] pred counts=[434, 16]\n[Sanity] Epoch 05/25 train_loss=0.8031 train_acc=0.5157 val_acc=0.5178\n[Sanity] Val true counts=[229, 221] pred counts=[408, 42]\n[Sanity] Epoch 10/25 train_loss=0.7679 train_acc=0.5037 val_acc=0.5267\n[Sanity] Val true counts=[229, 221] pred counts=[106, 344]\n[Sanity] Epoch 15/25 train_loss=0.7906 train_acc=0.5060 val_acc=0.5600\n[Sanity] Val true counts=[229, 221] pred counts=[165, 285]\n[Sanity] Epoch 20/25 train_loss=0.7917 train_acc=0.5345 val_acc=0.5311\n[Sanity] Val true counts=[229, 221] pred counts=[106, 344]\n[Sanity] Epoch 25/25 train_loss=0.8966 train_acc=0.5202 val_acc=0.5022\n[Sanity] Val true counts=[229, 221] pred counts=[441, 9]\n[Sanity] Best val acc: 0.5600\n\n  AMP enabled=True\n  Initial stage=stage1_head_only | Trainable params head=51,970 encoder=0\n  Optimizer LR  | head=0.0001 weight_decay=0.0001\n  Scheduler | total_steps=11000 warmup_steps=1100 warmup_ratio=0.1\n  Epochs: 200  |  Early-stop patience: 40\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/4020488252.py:432: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n/tmp/ipykernel_55/4020488252.py:556: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n/tmp/ipykernel_55/4020488252.py:582: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 001/200 | Train loss=1.5078 acc=0.5014 | Val loss=1.3430 acc=0.5089\n  LRs=[5.090909090909091e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage1_head_only\n  New best (mcc=0.0000, val_acc=0.5089) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=1.1997 acc=0.4980 | Val loss=0.8896 acc=0.5089\n  LRs=[1.0090909090909092e-05]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage1_head_only\nEpoch 003/200 | Train loss=0.8698 acc=0.5009 | Val loss=0.6939 acc=0.4978\n  LRs=[1.5090909090909091e-05]\n  Val true counts=[229, 221] pred counts=[323, 127]\n  Val per-class acc=[0.7117903828620911, 0.2760181128978729]\n  Val bal_acc=0.4939 val_mcc=-0.0135\n  Selection metric (mcc)=-0.0135 | stage=stage1_head_only\nEpoch 004/200 | Train loss=0.7943 acc=0.5368 | Val loss=0.6939 acc=0.5111\n  LRs=[2.009090909090909e-05]\n  Val true counts=[229, 221] pred counts=[255, 195]\n  Val per-class acc=[0.5764192342758179, 0.44343891739845276]\n  Val bal_acc=0.5099 val_mcc=0.0200\n  Selection metric (mcc)=0.0200 | stage=stage1_head_only\n  New best (mcc=0.0200, val_acc=0.5111) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 005/200 | Train loss=0.8139 acc=0.5009 | Val loss=0.6943 acc=0.5111\n  LRs=[2.5090909090909094e-05]\n  Val true counts=[229, 221] pred counts=[95, 355]\n  Val per-class acc=[0.22707423567771912, 0.8054298758506775]\n  Val bal_acc=0.5163 val_mcc=0.0398\n  Selection metric (mcc)=0.0398 | stage=stage1_head_only\n  New best (mcc=0.0398, val_acc=0.5111) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 006/200 | Train loss=0.8239 acc=0.4929 | Val loss=0.6988 acc=0.5089\n  LRs=[3.0090909090909093e-05]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage1_head_only\nEpoch 007/200 | Train loss=0.7911 acc=0.4969 | Val loss=0.6985 acc=0.5089\n  LRs=[3.509090909090909e-05]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage1_head_only\nEpoch 008/200 | Train loss=0.7873 acc=0.5009 | Val loss=0.7019 acc=0.4911\n  LRs=[4.009090909090909e-05]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage1_head_only\nEpoch 009/200 | Train loss=0.7656 acc=0.5066 | Val loss=0.6936 acc=0.5067\n  LRs=[4.5090909090909095e-05]\n  Val true counts=[229, 221] pred counts=[415, 35]\n  Val per-class acc=[0.9213973879814148, 0.07692307978868484]\n  Val bal_acc=0.4992 val_mcc=-0.0031\n  Selection metric (mcc)=-0.0031 | stage=stage1_head_only\nEpoch 010/200 | Train loss=0.7573 acc=0.4980 | Val loss=0.6938 acc=0.5000\n  LRs=[5.009090909090909e-05]\n  Val true counts=[229, 221] pred counts=[438, 12]\n  Val per-class acc=[0.9650654792785645, 0.018099548295140266]\n  Val bal_acc=0.4916 val_mcc=-0.0522\n  Selection metric (mcc)=-0.0522 | stage=stage1_head_only\nEpoch 011/200 | Train loss=0.7387 acc=0.5026 | Val loss=0.6944 acc=0.4956\n  LRs=[5.5090909090909094e-05]\n  Val true counts=[229, 221] pred counts=[86, 364]\n  Val per-class acc=[0.19213974475860596, 0.8099547624588013]\n  Val bal_acc=0.5010 val_mcc=0.0027\n  Selection metric (mcc)=0.0027 | stage=stage1_head_only\nEpoch 012/200 | Train loss=0.7374 acc=0.4957 | Val loss=0.6936 acc=0.5067\n  LRs=[6.00909090909091e-05]\n  Val true counts=[229, 221] pred counts=[383, 67]\n  Val per-class acc=[0.8515284061431885, 0.1493212729692459]\n  Val bal_acc=0.5004 val_mcc=0.0012\n  Selection metric (mcc)=0.0012 | stage=stage1_head_only\n\n  Stage switch at epoch 13: stage2_unfreeze_last_2 | Trainable params head=51,970 encoder=966,160\n  Optimizer LRs | head=5e-05 encoder=5e-06 weight_decay=0.0001\n  Scheduler reset | total_steps=10340 warmup_steps=1034\n\nEpoch 013/200 | Train loss=0.7294 acc=0.5077 | Val loss=0.6937 acc=0.5378\n  LRs=[2.707930367504836e-06, 2.707930367504836e-07]\n  Val true counts=[229, 221] pred counts=[323, 127]\n  Val per-class acc=[0.751091718673706, 0.31674209237098694]\n  Val bal_acc=0.5339 val_mcc=0.0753\n  Selection metric (mcc)=0.0753 | stage=stage2_unfreeze_last_2\n  New best (mcc=0.0753, val_acc=0.5378) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 014/200 | Train loss=0.7311 acc=0.4986 | Val loss=0.6938 acc=0.5267\n  LRs=[5.367504835589942e-06, 5.367504835589942e-07]\n  Val true counts=[229, 221] pred counts=[268, 182]\n  Val per-class acc=[0.6200873255729675, 0.4298642575740814]\n  Val bal_acc=0.5250 val_mcc=0.0509\n  Selection metric (mcc)=0.0509 | stage=stage2_unfreeze_last_2\nEpoch 015/200 | Train loss=0.7300 acc=0.5020 | Val loss=0.6937 acc=0.5133\n  LRs=[8.02707930367505e-06, 8.027079303675049e-07]\n  Val true counts=[229, 221] pred counts=[358, 92]\n  Val per-class acc=[0.8034934401512146, 0.21266968548297882]\n  Val bal_acc=0.5081 val_mcc=0.0200\n  Selection metric (mcc)=0.0200 | stage=stage2_unfreeze_last_2\nEpoch 016/200 | Train loss=0.7347 acc=0.4860 | Val loss=0.6937 acc=0.5044\n  LRs=[1.0686653771760155e-05, 1.0686653771760155e-06]\n  Val true counts=[229, 221] pred counts=[430, 20]\n  Val per-class acc=[0.9519650936126709, 0.04072398319840431]\n  Val bal_acc=0.4963 val_mcc=-0.0177\n  Selection metric (mcc)=-0.0177 | stage=stage2_unfreeze_last_2\nEpoch 017/200 | Train loss=0.7234 acc=0.5020 | Val loss=0.6937 acc=0.5133\n  LRs=[1.3346228239845262e-05, 1.3346228239845263e-06]\n  Val true counts=[229, 221] pred counts=[366, 84]\n  Val per-class acc=[0.8209607005119324, 0.1945701390504837]\n  Val bal_acc=0.5078 val_mcc=0.0199\n  Selection metric (mcc)=0.0199 | stage=stage2_unfreeze_last_2\nEpoch 018/200 | Train loss=0.7367 acc=0.4872 | Val loss=0.6939 acc=0.5200\n  LRs=[1.6005802707930368e-05, 1.6005802707930367e-06]\n  Val true counts=[229, 221] pred counts=[269, 181]\n  Val per-class acc=[0.6157205104827881, 0.42081448435783386]\n  Val bal_acc=0.5183 val_mcc=0.0372\n  Selection metric (mcc)=0.0372 | stage=stage2_unfreeze_last_2\nEpoch 019/200 | Train loss=0.7284 acc=0.4991 | Val loss=0.6943 acc=0.4956\n  LRs=[1.8665377176015476e-05, 1.8665377176015475e-06]\n  Val true counts=[229, 221] pred counts=[34, 416]\n  Val per-class acc=[0.0786026194691658, 0.9276018142700195]\n  Val bal_acc=0.5031 val_mcc=0.0117\n  Selection metric (mcc)=0.0117 | stage=stage2_unfreeze_last_2\nEpoch 020/200 | Train loss=0.7130 acc=0.5179 | Val loss=0.6947 acc=0.5089\n  LRs=[2.1324951644100583e-05, 2.132495164410058e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 021/200 | Train loss=0.7273 acc=0.4957 | Val loss=0.6947 acc=0.5044\n  LRs=[2.3984526112185687e-05, 2.398452611218569e-06]\n  Val true counts=[229, 221] pred counts=[32, 418]\n  Val per-class acc=[0.08296943455934525, 0.9411764740943909]\n  Val bal_acc=0.5121 val_mcc=0.0470\n  Selection metric (mcc)=0.0470 | stage=stage2_unfreeze_last_2\nEpoch 022/200 | Train loss=0.7159 acc=0.5088 | Val loss=0.6934 acc=0.5022\n  LRs=[2.664410058027079e-05, 2.6644100580270793e-06]\n  Val true counts=[229, 221] pred counts=[389, 61]\n  Val per-class acc=[0.8602620363235474, 0.1312217265367508]\n  Val bal_acc=0.4957 val_mcc=-0.0124\n  Selection metric (mcc)=-0.0124 | stage=stage2_unfreeze_last_2\nEpoch 023/200 | Train loss=0.7086 acc=0.5048 | Val loss=0.6935 acc=0.5133\n  LRs=[2.9303675048355898e-05, 2.93036750483559e-06]\n  Val true counts=[229, 221] pred counts=[400, 50]\n  Val per-class acc=[0.8951964974403381, 0.11764705926179886]\n  Val bal_acc=0.5064 val_mcc=0.0204\n  Selection metric (mcc)=0.0204 | stage=stage2_unfreeze_last_2\nEpoch 024/200 | Train loss=0.7146 acc=0.5003 | Val loss=0.6936 acc=0.5133\n  LRs=[3.196324951644101e-05, 3.196324951644101e-06]\n  Val true counts=[229, 221] pred counts=[182, 268]\n  Val per-class acc=[0.4192139804363251, 0.610859751701355]\n  Val bal_acc=0.5150 val_mcc=0.0306\n  Selection metric (mcc)=0.0306 | stage=stage2_unfreeze_last_2\nEpoch 025/200 | Train loss=0.7092 acc=0.5009 | Val loss=0.6978 acc=0.4911\n  LRs=[3.462282398452611e-05, 3.462282398452612e-06]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 026/200 | Train loss=0.7154 acc=0.4957 | Val loss=0.6937 acc=0.5111\n  LRs=[3.7282398452611224e-05, 3.728239845261122e-06]\n  Val true counts=[229, 221] pred counts=[317, 133]\n  Val per-class acc=[0.7117903828620911, 0.3031674325466156]\n  Val bal_acc=0.5075 val_mcc=0.0164\n  Selection metric (mcc)=0.0164 | stage=stage2_unfreeze_last_2\nEpoch 027/200 | Train loss=0.7038 acc=0.5134 | Val loss=0.6971 acc=0.5089\n  LRs=[3.994197292069633e-05, 3.994197292069633e-06]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 028/200 | Train loss=0.7014 acc=0.5123 | Val loss=0.6948 acc=0.5000\n  LRs=[4.260154738878143e-05, 4.260154738878143e-06]\n  Val true counts=[229, 221] pred counts=[16, 434]\n  Val per-class acc=[0.043668121099472046, 0.9728506803512573]\n  Val bal_acc=0.5083 val_mcc=0.0446\n  Selection metric (mcc)=0.0446 | stage=stage2_unfreeze_last_2\nEpoch 029/200 | Train loss=0.7055 acc=0.5219 | Val loss=0.7042 acc=0.4911\n  LRs=[4.526112185686654e-05, 4.526112185686654e-06]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 030/200 | Train loss=0.7056 acc=0.4963 | Val loss=0.6941 acc=0.5244\n  LRs=[4.7920696324951647e-05, 4.792069632495165e-06]\n  Val true counts=[229, 221] pred counts=[249, 201]\n  Val per-class acc=[0.5764192342758179, 0.47058823704719543]\n  Val bal_acc=0.5235 val_mcc=0.0473\n  Selection metric (mcc)=0.0473 | stage=stage2_unfreeze_last_2\nEpoch 031/200 | Train loss=0.6975 acc=0.5276 | Val loss=0.6984 acc=0.4911\n  LRs=[np.float64(4.999982762728059e-05), np.float64(4.99998276272806e-06)]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 032/200 | Train loss=0.7032 acc=0.5071 | Val loss=0.6947 acc=0.5067\n  LRs=[np.float64(4.999379483168148e-05), np.float64(4.999379483168148e-06)]\n  Val true counts=[229, 221] pred counts=[397, 53]\n  Val per-class acc=[0.8820960521697998, 0.11764705926179886]\n  Val bal_acc=0.4999 val_mcc=-0.0004\n  Selection metric (mcc)=-0.0004 | stage=stage2_unfreeze_last_2\nEpoch 033/200 | Train loss=0.7036 acc=0.5105 | Val loss=0.6980 acc=0.4933\n  LRs=[np.float64(4.997914577695306e-05), np.float64(4.997914577695306e-06)]\n  Val true counts=[229, 221] pred counts=[3, 447]\n  Val per-class acc=[0.008733624592423439, 0.9954751133918762]\n  Val bal_acc=0.5021 val_mcc=0.0259\n  Selection metric (mcc)=0.0259 | stage=stage2_unfreeze_last_2\nEpoch 034/200 | Train loss=0.7017 acc=0.4940 | Val loss=0.6950 acc=0.5222\n  LRs=[np.float64(4.995588551315087e-05), np.float64(4.995588551315087e-06)]\n  Val true counts=[229, 221] pred counts=[358, 92]\n  Val per-class acc=[0.8122270703315735, 0.22171945869922638]\n  Val bal_acc=0.5170 val_mcc=0.0421\n  Selection metric (mcc)=0.0421 | stage=stage2_unfreeze_last_2\nEpoch 035/200 | Train loss=0.6986 acc=0.5031 | Val loss=0.6951 acc=0.5067\n  LRs=[np.float64(4.992402205892358e-05), np.float64(4.992402205892359e-06)]\n  Val true counts=[229, 221] pred counts=[375, 75]\n  Val per-class acc=[0.8340611457824707, 0.16742081940174103]\n  Val bal_acc=0.5007 val_mcc=0.0020\n  Selection metric (mcc)=0.0020 | stage=stage2_unfreeze_last_2\nEpoch 036/200 | Train loss=0.6965 acc=0.5231 | Val loss=0.6980 acc=0.5089\n  LRs=[np.float64(4.9883566398748774e-05), np.float64(4.988356639874877e-06)]\n  Val true counts=[229, 221] pred counts=[448, 2]\n  Val per-class acc=[0.9956331849098206, 0.004524887073785067]\n  Val bal_acc=0.5001 val_mcc=0.0012\n  Selection metric (mcc)=0.0012 | stage=stage2_unfreeze_last_2\nEpoch 037/200 | Train loss=0.6964 acc=0.5140 | Val loss=0.6953 acc=0.5178\n  LRs=[np.float64(4.98345324791461e-05), np.float64(4.98345324791461e-06)]\n  Val true counts=[229, 221] pred counts=[278, 172]\n  Val per-class acc=[0.6331877708435059, 0.39819005131721497]\n  Val bal_acc=0.5157 val_mcc=0.0323\n  Selection metric (mcc)=0.0323 | stage=stage2_unfreeze_last_2\nEpoch 038/200 | Train loss=0.7019 acc=0.5020 | Val loss=0.6955 acc=0.4889\n  LRs=[np.float64(4.97769372038695e-05), np.float64(4.977693720386951e-06)]\n  Val true counts=[229, 221] pred counts=[145, 305]\n  Val per-class acc=[0.3144104778766632, 0.6696832776069641]\n  Val bal_acc=0.4920 val_mcc=-0.0170\n  Selection metric (mcc)=-0.0170 | stage=stage2_unfreeze_last_2\nEpoch 039/200 | Train loss=0.6934 acc=0.5117 | Val loss=0.6963 acc=0.4911\n  LRs=[np.float64(4.971080042807981e-05), np.float64(4.971080042807981e-06)]\n  Val true counts=[229, 221] pred counts=[72, 378]\n  Val per-class acc=[0.1572052389383316, 0.837104082107544]\n  Val bal_acc=0.4972 val_mcc=-0.0078\n  Selection metric (mcc)=-0.0078 | stage=stage2_unfreeze_last_2\nEpoch 040/200 | Train loss=0.6956 acc=0.5066 | Val loss=0.6992 acc=0.5089\n  LRs=[np.float64(4.96361449515e-05), np.float64(4.96361449515e-06)]\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 041/200 | Train loss=0.6958 acc=0.5208 | Val loss=0.7016 acc=0.4911\n  LRs=[np.float64(4.955299651055528e-05), np.float64(4.9552996510555284e-06)]\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\n  Val bal_acc=0.5000 val_mcc=0.0000\n  Selection metric (mcc)=0.0000 | stage=stage2_unfreeze_last_2\nEpoch 042/200 | Train loss=0.6922 acc=0.5254 | Val loss=0.6948 acc=0.5089\n  LRs=[np.float64(4.946138376950087e-05), np.float64(4.946138376950087e-06)]\n  Val true counts=[229, 221] pred counts=[240, 210]\n  Val per-class acc=[0.5414847135543823, 0.4751131236553192]\n  Val bal_acc=0.5083 val_mcc=0.0166\n  Selection metric (mcc)=0.0166 | stage=stage2_unfreeze_last_2\nEpoch 043/200 | Train loss=0.6972 acc=0.5088 | Val loss=0.6951 acc=0.5133\n  LRs=[np.float64(4.936133831054032e-05), np.float64(4.936133831054032e-06)]\n  Val true counts=[229, 221] pred counts=[420, 30]\n  Val per-class acc=[0.9388646483421326, 0.07239819318056107]\n  Val bal_acc=0.5056 val_mcc=0.0226\n  Selection metric (mcc)=0.0226 | stage=stage2_unfreeze_last_2\nEpoch 044/200 | Train loss=0.6939 acc=0.5231 | Val loss=0.6942 acc=0.5022\n  LRs=[np.float64(4.925289462293807e-05), np.float64(4.925289462293807e-06)]\n  Val true counts=[229, 221] pred counts=[357, 93]\n  Val per-class acc=[0.7903929948806763, 0.20361991226673126]\n  Val bal_acc=0.4970 val_mcc=-0.0074\n  Selection metric (mcc)=-0.0074 | stage=stage2_unfreeze_last_2\nEpoch 045/200 | Train loss=0.6955 acc=0.5037 | Val loss=0.6947 acc=0.5000\n  LRs=[np.float64(4.9136090091129725e-05), np.float64(4.913609009112972e-06)]\n  Val true counts=[229, 221] pred counts=[212, 238]\n  Val per-class acc=[0.471615731716156, 0.529411792755127]\n  Val bal_acc=0.5005 val_mcc=0.0010\n  Selection metric (mcc)=0.0010 | stage=stage2_unfreeze_last_2\nEpoch 046/200 | Train loss=0.6924 acc=0.5282 | Val loss=0.6953 acc=0.4889\n  LRs=[np.float64(4.901096498183429e-05), np.float64(4.901096498183429e-06)]\n  Val true counts=[229, 221] pred counts=[67, 383]\n  Val per-class acc=[0.14410480856895447, 0.8461538553237915]\n  Val bal_acc=0.4951 val_mcc=-0.0137\n  Selection metric (mcc)=-0.0137 | stage=stage2_unfreeze_last_2\nEpoch 047/200 | Train loss=0.6950 acc=0.5168 | Val loss=0.6950 acc=0.5067\n  LRs=[np.float64(4.8877562430172815e-05), np.float64(4.887756243017282e-06)]\n  Val true counts=[229, 221] pred counts=[423, 27]\n  Val per-class acc=[0.9388646483421326, 0.05882352963089943]\n  Val bal_acc=0.4988 val_mcc=-0.0049\n  Selection metric (mcc)=-0.0049 | stage=stage2_unfreeze_last_2\nEpoch 048/200 | Train loss=0.6943 acc=0.5031 | Val loss=0.6940 acc=0.5067\n  LRs=[np.float64(4.873592842479813e-05), np.float64(4.873592842479813e-06)]\n  Val true counts=[229, 221] pred counts=[371, 79]\n  Val per-class acc=[0.8253275156021118, 0.1764705926179886]\n  Val bal_acc=0.5009 val_mcc=0.0024\n  Selection metric (mcc)=0.0024 | stage=stage2_unfreeze_last_2\nEpoch 049/200 | Train loss=0.6930 acc=0.5179 | Val loss=0.6981 acc=0.4978\n  LRs=[np.float64(4.8586111792040935e-05), np.float64(4.858611179204094e-06)]\n  Val true counts=[229, 221] pred counts=[5, 445]\n  Val per-class acc=[0.017467249184846878, 0.9954751133918762]\n  Val bal_acc=0.5065 val_mcc=0.0617\n  Selection metric (mcc)=0.0617 | stage=stage2_unfreeze_last_2\nEpoch 050/200 | Train loss=0.6948 acc=0.5191 | Val loss=0.6943 acc=0.5067\n  LRs=[np.float64(4.842816417907759e-05), np.float64(4.8428164179077595e-06)]\n  Val true counts=[229, 221] pred counts=[383, 67]\n  Val per-class acc=[0.8515284061431885, 0.1493212729692459]\n  Val bal_acc=0.5004 val_mcc=0.0012\n  Selection metric (mcc)=0.0012 | stage=stage2_unfreeze_last_2\nEpoch 051/200 | Train loss=0.6948 acc=0.5140 | Val loss=0.6966 acc=0.5067\n  LRs=[np.float64(4.82621400361255e-05), np.float64(4.82621400361255e-06)]\n  Val true counts=[229, 221] pred counts=[441, 9]\n  Val per-class acc=[0.9781659245491028, 0.018099548295140266]\n  Val bal_acc=0.4981 val_mcc=-0.0133\n  Selection metric (mcc)=-0.0133 | stage=stage2_unfreeze_last_2\nEpoch 052/200 | Train loss=0.6924 acc=0.5299 | Val loss=0.6947 acc=0.5067\n  LRs=[np.float64(4.808809659767214e-05), np.float64(4.808809659767214e-06)]\n  Val true counts=[229, 221] pred counts=[371, 79]\n  Val per-class acc=[0.8253275156021118, 0.1764705926179886]\n  Val bal_acc=0.5009 val_mcc=0.0024\n  Selection metric (mcc)=0.0024 | stage=stage2_unfreeze_last_2\nEpoch 053/200 | Train loss=0.6956 acc=0.5117 | Val loss=0.6938 acc=0.5111\n  LRs=[np.float64(4.7906093862744297e-05), np.float64(4.79060938627443e-06)]\n  Val true counts=[229, 221] pred counts=[303, 147]\n  Val per-class acc=[0.6812227368354797, 0.33484163880348206]\n  Val bal_acc=0.5080 val_mcc=0.0171\n  Selection metric (mcc)=0.0171 | stage=stage2_unfreeze_last_2\n\nEarly stopping at epoch 53.\n\nTraining complete. Best mcc: 0.0753 | Best val_acc: 0.5378 | Best val_bal_acc: 0.5339 | Best val_mcc: 0.0753\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Archive","metadata":{}},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.freeze_encoder:\n            with torch.no_grad():\n                tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n        else:\n            tokens = self.encoder(\n                x, channel_names=self.channel_names, return_patch_tokens=True\n            )\n\n        pooled = self._pool_tokens(tokens)\n        return self.classifier(pooled)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\n\n# y_train_t is class ids like [0,1,2]\n# class_counts = torch.bincount(y_train_t, minlength=config[\"model\"][\"num_classes\"]).float()\n# class_weights = 1.0 / class_counts.clamp(min=1)   # inverse frequency\n# sample_weights = class_weights[y_train_t]         # weight per sample\n# sampler = WeightedRandomSampler(\n#   weights=sample_weights.double(),\n#   num_samples=len(sample_weights),\n#   replacement=True,\n# )\n\ntrain_loader = DataLoader(\n    TensorDataset(X_train_t, y_train_t), batch_size=batch_size, \n    # sampler=sampler, shuffle=False,\n    shuffle=True\n)\nval_loader = DataLoader(\n    TensorDataset(X_val_t, y_val_t), batch_size=batch_size, \n    # sampler=sampler, shuffle=False,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=model_cfg[\"num_classes\"],\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    pooling=model_cfg.get(\"pooling\", \"mean\"),\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ncounts = np.bincount(y_train)\nweights = len(y_train) / (len(counts) * counts)\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n\n# criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"])\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses, train_accs = [], []\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        acc = (logits.argmax(1) == y_batch).float().mean().item()\n        train_losses.append(loss.item())\n        train_accs.append(acc)\n\n    model.eval()\n    val_losses, val_accs = [], []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n            acc = (logits.argmax(1) == y_batch).float().mean().item()\n            val_losses.append(loss.item())\n            val_accs.append(acc)\n\n    train_loss = np.mean(train_losses)\n    train_acc = np.mean(train_accs)\n    val_loss = np.mean(val_losses)\n    val_acc = np.mean(val_accs)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T05:34:52.669336Z","iopub.execute_input":"2026-02-28T05:34:52.669604Z","iopub.status.idle":"2026-02-28T05:39:44.662314Z","shell.execute_reply.started":"2026-02-28T05:34:52.669582Z","shell.execute_reply":"2026-02-28T05:39:44.661575Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n\n  Device: cuda\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=1.1489 acc=0.3428 | Val loss=1.1256 acc=0.2457\n  New best (0.2457) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=1.1076 acc=0.3425 | Val loss=1.1024 acc=0.2457\nEpoch 003/200 | Train loss=1.1015 acc=0.3218 | Val loss=1.1021 acc=0.2457\nEpoch 004/200 | Train loss=1.1002 acc=0.4111 | Val loss=1.0992 acc=0.5000\n  New best (0.5000) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 005/200 | Train loss=1.0990 acc=0.4867 | Val loss=1.0987 acc=0.5000\nEpoch 006/200 | Train loss=1.0997 acc=0.4101 | Val loss=1.0988 acc=0.5000\nEpoch 007/200 | Train loss=1.0989 acc=0.4830 | Val loss=1.0988 acc=0.5000\nEpoch 008/200 | Train loss=1.1002 acc=0.4849 | Val loss=1.0988 acc=0.5000\nEpoch 009/200 | Train loss=1.0988 acc=0.4986 | Val loss=1.0988 acc=0.5000\nEpoch 010/200 | Train loss=1.0987 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 011/200 | Train loss=1.0986 acc=0.5001 | Val loss=1.0987 acc=0.5000\nEpoch 012/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0987 acc=0.5000\nEpoch 013/200 | Train loss=1.0987 acc=0.4994 | Val loss=1.0987 acc=0.5000\nEpoch 014/200 | Train loss=1.0991 acc=0.4777 | Val loss=1.0987 acc=0.5000\nEpoch 015/200 | Train loss=1.0988 acc=0.4859 | Val loss=1.0987 acc=0.5000\nEpoch 016/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0987 acc=0.5000\nEpoch 017/200 | Train loss=1.0987 acc=0.5003 | Val loss=1.0987 acc=0.5000\nEpoch 018/200 | Train loss=1.0987 acc=0.5003 | Val loss=1.0987 acc=0.5000\nEpoch 019/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0987 acc=0.5000\nEpoch 020/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0987 acc=0.5000\nEpoch 021/200 | Train loss=1.0987 acc=0.4995 | Val loss=1.0987 acc=0.5000\nEpoch 022/200 | Train loss=1.0987 acc=0.5001 | Val loss=1.0987 acc=0.5000\nEpoch 023/200 | Train loss=1.0986 acc=0.5005 | Val loss=1.0986 acc=0.5000\nEpoch 024/200 | Train loss=1.0986 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 025/200 | Train loss=1.0989 acc=0.4651 | Val loss=1.0986 acc=0.5000\nEpoch 026/200 | Train loss=1.0986 acc=0.4996 | Val loss=1.0987 acc=0.5000\nEpoch 027/200 | Train loss=1.0987 acc=0.5004 | Val loss=1.0987 acc=0.5000\nEpoch 028/200 | Train loss=1.0987 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 029/200 | Train loss=1.0987 acc=0.5000 | Val loss=1.0987 acc=0.5000\nEpoch 030/200 | Train loss=1.0987 acc=0.5001 | Val loss=1.0987 acc=0.5000\nEpoch 031/200 | Train loss=1.0989 acc=0.4621 | Val loss=1.0987 acc=0.5000\nEpoch 032/200 | Train loss=1.0987 acc=0.5000 | Val loss=1.0987 acc=0.5000\nEpoch 033/200 | Train loss=1.0987 acc=0.4996 | Val loss=1.0987 acc=0.5000\nEpoch 034/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0988 acc=0.5000\nEpoch 035/200 | Train loss=1.0987 acc=0.4908 | Val loss=1.0987 acc=0.5000\nEpoch 036/200 | Train loss=1.0987 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 037/200 | Train loss=1.0987 acc=0.5001 | Val loss=1.0987 acc=0.5000\nEpoch 038/200 | Train loss=1.0987 acc=0.5004 | Val loss=1.0987 acc=0.5000\nEpoch 039/200 | Train loss=1.0987 acc=0.5004 | Val loss=1.0987 acc=0.5000\nEpoch 040/200 | Train loss=1.0987 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 041/200 | Train loss=1.0987 acc=0.4970 | Val loss=1.0987 acc=0.5000\nEpoch 042/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0987 acc=0.5000\nEpoch 043/200 | Train loss=1.0987 acc=0.4999 | Val loss=1.0987 acc=0.5000\nEpoch 044/200 | Train loss=1.0987 acc=0.4997 | Val loss=1.0986 acc=0.5000\n\nEarly stopping at epoch 44.\n\nTraining complete. Best val acc: 0.5000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            tokens = self.encoder(\n                x, channel_names=self.channel_names, return_patch_tokens=True\n            )\n        else:\n            with torch.no_grad():\n                tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n\n        pooled = self._pool_tokens(tokens)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\n\n# y_train_t is class ids like [0,1,2]\nclass_counts = torch.bincount(y_train_t, minlength=config[\"model\"][\"num_classes\"]).float()\nclass_weights = 1.0 / class_counts.clamp(min=1)   # inverse frequency\nsample_weights = class_weights[y_train_t]         # weight per sample\nsampler = WeightedRandomSampler(\n  weights=sample_weights.double(),\n  num_samples=len(sample_weights),\n  replacement=True,\n)\n\ntrain_loader = DataLoader(\n    TensorDataset(X_train_t, y_train_t), batch_size=batch_size, \n    sampler=sampler, shuffle=False,\n    # shuffle=True\n)\nval_loader = DataLoader(\n    TensorDataset(X_val_t, y_val_t), batch_size=batch_size, \n    # sampler=sampler, shuffle=False,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=model_cfg[\"num_classes\"],\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    unfreeze_last_n_blocks=4,#model_cfg.get(\"unfreeze_last_n_blocks\", 0),\n    pooling=model_cfg.get(\"pooling\", \"mean\"),\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ncounts = np.bincount(y_train)\nweights = len(y_train) / (len(counts) * counts)\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"])\n\nhead_lr = config[\"training\"][\"learning_rate\"]\nencoder_lr = config[\"training\"].get(\"encoder_learning_rate\", 1e-5)\nweight_decay = config[\"training\"].get(\"weight_decay\", 0.0)\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model_cfg.get('unfreeze_last_n_blocks', 0)})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses, train_accs = [], []\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        acc = (logits.argmax(1) == y_batch).float().mean().item()\n        train_losses.append(loss.item())\n        train_accs.append(acc)\n\n    model.eval()\n    val_losses, val_accs = [], []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n            acc = (logits.argmax(1) == y_batch).float().mean().item()\n            val_losses.append(loss.item())\n            val_accs.append(acc)\n\n    train_loss = np.mean(train_losses)\n    train_acc = np.mean(train_accs)\n    val_loss = np.mean(val_losses)\n    val_acc = np.mean(val_accs)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T05:51:49.781878Z","iopub.execute_input":"2026-02-28T05:51:49.782441Z","iopub.status.idle":"2026-02-28T05:56:26.264965Z","shell.execute_reply.started":"2026-02-28T05:51:49.782413Z","shell.execute_reply":"2026-02-28T05:56:26.264121Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n\n  Device: cuda\n  Trainable params | head=52,227 encoder=1,931,920 (unfreeze_last_n_blocks=2)\n  Optimizer LRs | head=0.001 encoder=1e-05 weight_decay=0.01\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=1.1171 acc=0.3293 | Val loss=1.1347 acc=0.2457\n  New best (0.2457) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=1.0692 acc=0.3351 | Val loss=1.1217 acc=0.2457\nEpoch 003/200 | Train loss=1.0664 acc=0.3344 | Val loss=1.1265 acc=0.2543\n  New best (0.2543) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 004/200 | Train loss=1.0558 acc=0.3351 | Val loss=1.1439 acc=0.2457\nEpoch 005/200 | Train loss=1.0610 acc=0.3214 | Val loss=1.1517 acc=0.2457\nEpoch 006/200 | Train loss=1.0631 acc=0.3306 | Val loss=1.1638 acc=0.2543\nEpoch 007/200 | Train loss=1.0627 acc=0.3314 | Val loss=1.1319 acc=0.2457\nEpoch 008/200 | Train loss=1.0596 acc=0.3276 | Val loss=1.1393 acc=0.2543\nEpoch 009/200 | Train loss=1.0590 acc=0.3270 | Val loss=1.1542 acc=0.2457\nEpoch 010/200 | Train loss=1.0608 acc=0.3374 | Val loss=1.1401 acc=0.2457\nEpoch 011/200 | Train loss=1.0590 acc=0.3251 | Val loss=1.1330 acc=0.2543\nEpoch 012/200 | Train loss=1.0608 acc=0.3300 | Val loss=1.1477 acc=0.2543\nEpoch 013/200 | Train loss=1.0633 acc=0.3304 | Val loss=1.1420 acc=0.2457\nEpoch 014/200 | Train loss=1.0625 acc=0.3300 | Val loss=1.1374 acc=0.2457\nEpoch 015/200 | Train loss=1.0687 acc=0.3269 | Val loss=1.1360 acc=0.2543\nEpoch 016/200 | Train loss=1.0615 acc=0.3312 | Val loss=1.1459 acc=0.2457\nEpoch 017/200 | Train loss=1.0575 acc=0.3473 | Val loss=1.1374 acc=0.2457\nEpoch 018/200 | Train loss=1.0603 acc=0.3252 | Val loss=1.1161 acc=0.2457\nEpoch 019/200 | Train loss=1.0609 acc=0.3300 | Val loss=1.1225 acc=0.2457\nEpoch 020/200 | Train loss=1.0594 acc=0.3369 | Val loss=1.1324 acc=0.2543\nEpoch 021/200 | Train loss=1.0540 acc=0.3439 | Val loss=1.1491 acc=0.2543\nEpoch 022/200 | Train loss=1.0531 acc=0.3379 | Val loss=1.1627 acc=0.2457\nEpoch 023/200 | Train loss=1.0569 acc=0.3393 | Val loss=1.1452 acc=0.2543\nEpoch 024/200 | Train loss=1.0565 acc=0.3363 | Val loss=1.1392 acc=0.2543\nEpoch 025/200 | Train loss=1.0558 acc=0.3355 | Val loss=1.1569 acc=0.2457\nEpoch 026/200 | Train loss=1.0610 acc=0.3337 | Val loss=1.1385 acc=0.2457\nEpoch 027/200 | Train loss=1.0562 acc=0.3364 | Val loss=1.1284 acc=0.2457\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1193147976.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            tokens = self.encoder(\n                x, channel_names=self.channel_names, return_patch_tokens=True\n            )\n        else:\n            with torch.no_grad():\n                tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n\n        pooled = self._pool_tokens(tokens)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nnum_classes = config[\"model\"][\"num_classes\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = True\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=model_cfg[\"num_classes\"],\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    unfreeze_last_n_blocks=model_cfg.get(\"unfreeze_last_n_blocks\", 0),\n    pooling=model_cfg.get(\"pooling\", \"mean\"),\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(weight=ce_weights)\nelse:\n    criterion = nn.CrossEntropyLoss()\n\nhead_lr = config[\"training\"][\"learning_rate\"]\nencoder_lr = config[\"training\"].get(\"encoder_learning_rate\", 1e-5)\nweight_decay = config[\"training\"].get(\"weight_decay\", 0.0)\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model.unfreeze_last_n_blocks})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T05:56:32.329339Z","iopub.execute_input":"2026-02-28T05:56:32.329835Z","iopub.status.idle":"2026-02-28T06:02:13.407785Z","shell.execute_reply.started":"2026-02-28T05:56:32.329807Z","shell.execute_reply":"2026-02-28T06:02:13.407120Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Train class counts: [884.0, 871.0, 1755.0]\n  Val class counts:   [229.0, 221.0, 450.0]\n\n  Device: cuda\n  Trainable params | head=52,227 encoder=966,160 (unfreeze_last_n_blocks=2)\n  Optimizer LRs | head=0.001 encoder=1e-05 weight_decay=0.01\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=1.1433 acc=0.3379 | Val loss=1.0696 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\n  New best (0.5000) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=1.1067 acc=0.3330 | Val loss=1.0779 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 003/200 | Train loss=1.1010 acc=0.3410 | Val loss=1.0949 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 004/200 | Train loss=1.0996 acc=0.3376 | Val loss=1.1028 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 005/200 | Train loss=1.0994 acc=0.3387 | Val loss=1.0998 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 006/200 | Train loss=1.0990 acc=0.3274 | Val loss=1.0971 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 007/200 | Train loss=1.0986 acc=0.3422 | Val loss=1.0985 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 008/200 | Train loss=1.0985 acc=0.3396 | Val loss=1.0982 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 009/200 | Train loss=1.0988 acc=0.3353 | Val loss=1.0986 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 010/200 | Train loss=1.0990 acc=0.3299 | Val loss=1.0833 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 011/200 | Train loss=1.0989 acc=0.3393 | Val loss=1.1026 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 012/200 | Train loss=1.0988 acc=0.3251 | Val loss=1.1009 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 013/200 | Train loss=1.0988 acc=0.3410 | Val loss=1.1009 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 014/200 | Train loss=1.0986 acc=0.3493 | Val loss=1.0982 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 015/200 | Train loss=1.0985 acc=0.3390 | Val loss=1.0976 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 016/200 | Train loss=1.0989 acc=0.3276 | Val loss=1.0962 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 017/200 | Train loss=1.0988 acc=0.3299 | Val loss=1.0974 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 018/200 | Train loss=1.0988 acc=0.3225 | Val loss=1.1000 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 019/200 | Train loss=1.0986 acc=0.3376 | Val loss=1.1021 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 020/200 | Train loss=1.0987 acc=0.3359 | Val loss=1.0991 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 021/200 | Train loss=1.0987 acc=0.3282 | Val loss=1.0975 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 022/200 | Train loss=1.0991 acc=0.3308 | Val loss=1.0993 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 023/200 | Train loss=1.0986 acc=0.3402 | Val loss=1.0955 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 024/200 | Train loss=1.0982 acc=0.3467 | Val loss=1.0930 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 025/200 | Train loss=1.0987 acc=0.3373 | Val loss=1.0942 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 026/200 | Train loss=1.0988 acc=0.3342 | Val loss=1.0954 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 027/200 | Train loss=1.0986 acc=0.3387 | Val loss=1.0958 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 028/200 | Train loss=1.0987 acc=0.3299 | Val loss=1.0976 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 029/200 | Train loss=1.0987 acc=0.3370 | Val loss=1.0955 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 030/200 | Train loss=1.0986 acc=0.3399 | Val loss=1.0951 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 031/200 | Train loss=1.0987 acc=0.3274 | Val loss=1.0973 acc=0.5000\n  Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n  Val per-class acc=[0.0, 0.0, 1.0]\nEpoch 032/200 | Train loss=1.0986 acc=0.3464 | Val loss=1.0979 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 033/200 | Train loss=1.0984 acc=0.3530 | Val loss=1.1015 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 034/200 | Train loss=1.0991 acc=0.3302 | Val loss=1.1085 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 035/200 | Train loss=1.0989 acc=0.3291 | Val loss=1.0991 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 036/200 | Train loss=1.0987 acc=0.3353 | Val loss=1.0978 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 037/200 | Train loss=1.0987 acc=0.3396 | Val loss=1.1003 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\nEpoch 038/200 | Train loss=1.0986 acc=0.3348 | Val loss=1.1026 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 039/200 | Train loss=1.0984 acc=0.3405 | Val loss=1.1053 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 040/200 | Train loss=1.0989 acc=0.3288 | Val loss=1.0989 acc=0.2544\n  Val true counts=[229, 221, 450] pred counts=[900, 0, 0]\n  Val per-class acc=[1.0, 0.0, 0.0]\nEpoch 041/200 | Train loss=1.0987 acc=0.3219 | Val loss=1.0994 acc=0.2456\n  Val true counts=[229, 221, 450] pred counts=[0, 900, 0]\n  Val per-class acc=[0.0, 1.0, 0.0]\n\nEarly stopping at epoch 41.\n\nTraining complete. Best val acc: 0.5000\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        if self.pooling == \"cls\":\n            raise ValueError(\"CLS pooling is handled in forward() using class token.\")\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def encode(self, x: torch.Tensor, force_no_grad: bool = False) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            def _encode_inner():\n                if self.pooling == \"cls\":\n                    # (B, N*P+1, E); index 0 is class token\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    return tokens_all[:, 0, :]\n\n                patch_tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n                return self._pool_tokens(patch_tokens)\n\n            if force_no_grad:\n                with torch.no_grad():\n                    pooled = _encode_inner()\n            else:\n                pooled = _encode_inner()\n        else:\n            with torch.no_grad():\n                if self.pooling == \"cls\":\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    pooled = tokens_all[:, 0, :]\n                else:\n                    patch_tokens = self.encoder(\n                        x, channel_names=self.channel_names, return_patch_tokens=True\n                    )\n                    pooled = self._pool_tokens(patch_tokens)\n\n        return pooled\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        pooled = self.encode(x)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\ndef zscore_epochs(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n    # Per-epoch, per-channel normalization over time.\n    mu = X.mean(axis=-1, keepdims=True)\n    sd = X.std(axis=-1, keepdims=True)\n    return (X - mu) / (sd + eps)\n\nX_train = zscore_epochs(X_train)\nX_val = zscore_epochs(X_val)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nnum_classes = config[\"model\"][\"num_classes\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = True\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\npooling_mode = \"cls\"\nunfreeze_last_n_blocks = 0\nhead_lr = 1e-4\nencoder_lr = 1e-5\nweight_decay = config[\"training\"].get(\"weight_decay\", 0.01)\nprint(\n    f\"  Overrides | pooling={pooling_mode} \"\n    f\"unfreeze_last_n_blocks={unfreeze_last_n_blocks} \"\n    f\"head_lr={head_lr} encoder_lr={encoder_lr}\"\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=model_cfg[\"num_classes\"],\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    unfreeze_last_n_blocks=unfreeze_last_n_blocks,\n    pooling=pooling_mode,\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ndef run_linear_probe_sanity(\n    model: LaBraMProbe,\n    X_train_t: torch.Tensor,\n    y_train_t: torch.Tensor,\n    X_val_t: torch.Tensor,\n    y_val_t: torch.Tensor,\n    num_classes: int,\n    device: str,\n    batch_size: int = 256,\n    epochs: int = 25,\n    lr: float = 1e-2,\n):\n    print(\"\\n[Sanity] Running frozen-embedding linear probe...\")\n\n    def extract_features(X_tensor: torch.Tensor) -> torch.Tensor:\n        feat_loader = DataLoader(\n            TensorDataset(X_tensor), batch_size=batch_size, shuffle=False\n        )\n        features = []\n        model.eval()\n        with torch.no_grad():\n            for (x_batch,) in feat_loader:\n                x_batch = x_batch.to(device)\n                pooled = model.encode(x_batch, force_no_grad=True)\n                features.append(pooled.cpu())\n        return torch.cat(features, dim=0)\n\n    train_features = extract_features(X_train_t)\n    val_features = extract_features(X_val_t)\n    print(\n        f\"[Sanity] Feature shapes train={tuple(train_features.shape)} \"\n        f\"val={tuple(val_features.shape)}\"\n    )\n\n    linear_head = nn.Linear(train_features.shape[1], num_classes).to(device)\n    sanity_optimizer = optim.AdamW(linear_head.parameters(), lr=lr)\n    sanity_criterion = nn.CrossEntropyLoss()\n\n    sanity_train_loader = DataLoader(\n        TensorDataset(train_features, y_train_t), batch_size=batch_size, shuffle=True\n    )\n    sanity_val_loader = DataLoader(\n        TensorDataset(val_features, y_val_t), batch_size=batch_size, shuffle=False\n    )\n\n    best_val_acc = 0.0\n    for ep in range(1, epochs + 1):\n        linear_head.train()\n        train_correct = 0\n        train_total = 0\n        train_losses = []\n        for feat_batch, y_batch in sanity_train_loader:\n            feat_batch = feat_batch.to(device)\n            y_batch = y_batch.to(device)\n            sanity_optimizer.zero_grad()\n            logits = linear_head(feat_batch)\n            loss = sanity_criterion(logits, y_batch)\n            loss.backward()\n            sanity_optimizer.step()\n\n            preds = logits.argmax(1)\n            train_correct += (preds == y_batch).sum().item()\n            train_total += y_batch.numel()\n            train_losses.append(loss.item())\n\n        linear_head.eval()\n        val_correct = 0\n        val_total = 0\n        all_val_preds = []\n        all_val_targets = []\n        with torch.no_grad():\n            for feat_batch, y_batch in sanity_val_loader:\n                feat_batch = feat_batch.to(device)\n                y_batch = y_batch.to(device)\n                logits = linear_head(feat_batch)\n                preds = logits.argmax(1)\n                val_correct += (preds == y_batch).sum().item()\n                val_total += y_batch.numel()\n                all_val_preds.append(preds.cpu())\n                all_val_targets.append(y_batch.cpu())\n\n        train_acc = train_correct / max(train_total, 1)\n        val_acc = val_correct / max(val_total, 1)\n        best_val_acc = max(best_val_acc, val_acc)\n\n        if ep == 1 or ep % 5 == 0 or ep == epochs:\n            val_preds_flat = torch.cat(all_val_preds)\n            val_targets_flat = torch.cat(all_val_targets)\n            val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n            val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n            print(\n                f\"[Sanity] Epoch {ep:02d}/{epochs} \"\n                f\"train_loss={np.mean(train_losses):.4f} \"\n                f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n            )\n            print(\n                f\"[Sanity] Val true counts={val_true_counts.tolist()} \"\n                f\"pred counts={val_pred_counts.tolist()}\"\n            )\n\n    print(f\"[Sanity] Best val acc: {best_val_acc:.4f}\\n\")\n\n\nrun_linear_sanity_check = True\nif run_linear_sanity_check:\n    run_linear_probe_sanity(\n        model=model,\n        X_train_t=X_train_t,\n        y_train_t=y_train_t,\n        X_val_t=X_val_t,\n        y_val_t=y_val_t,\n        num_classes=num_classes,\n        device=device,\n        batch_size=batch_size,\n        epochs=25,\n        lr=1e-2,\n    )\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(weight=ce_weights)\nelse:\n    criterion = nn.CrossEntropyLoss()\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model.unfreeze_last_n_blocks})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:03:03.841462Z","iopub.execute_input":"2026-02-28T06:03:03.842105Z","iopub.status.idle":"2026-02-28T06:05:07.351162Z","shell.execute_reply.started":"2026-02-28T06:03:03.842074Z","shell.execute_reply":"2026-02-28T06:05:07.350148Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Train class counts: [884.0, 871.0, 1755.0]\n  Val class counts:   [229.0, 221.0, 450.0]\n  Overrides | pooling=cls unfreeze_last_n_blocks=0 head_lr=0.0001 encoder_lr=1e-05\n\n  Device: cuda\n\n[Sanity] Running frozen-embedding linear probe...\n[Sanity] Feature shapes train=(3510, 200) val=(900, 200)\n[Sanity] Epoch 01/25 train_loss=1.3238 train_acc=0.4145 val_acc=0.5000\n[Sanity] Val true counts=[229, 221, 450] pred counts=[0, 0, 900]\n[Sanity] Epoch 05/25 train_loss=1.2136 train_acc=0.4282 val_acc=0.4411\n[Sanity] Val true counts=[229, 221, 450] pred counts=[0, 223, 677]\n[Sanity] Epoch 10/25 train_loss=1.1301 train_acc=0.4407 val_acc=0.3656\n[Sanity] Val true counts=[229, 221, 450] pred counts=[513, 0, 387]\n[Sanity] Epoch 15/25 train_loss=1.1795 train_acc=0.4299 val_acc=0.2567\n[Sanity] Val true counts=[229, 221, 450] pred counts=[882, 0, 18]\n[Sanity] Epoch 20/25 train_loss=1.1627 train_acc=0.4274 val_acc=0.4867\n[Sanity] Val true counts=[229, 221, 450] pred counts=[37, 0, 863]\n[Sanity] Epoch 25/25 train_loss=1.1996 train_acc=0.4348 val_acc=0.4089\n[Sanity] Val true counts=[229, 221, 450] pred counts=[394, 0, 506]\n[Sanity] Best val acc: 0.5022\n\n  Trainable params | head=52,227 encoder=0 (unfreeze_last_n_blocks=0)\n  Optimizer LR  | head=0.0001 weight_decay=0.01\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=1.2427 acc=0.3442 | Val loss=1.0814 acc=0.4922\n  Val true counts=[229, 221, 450] pred counts=[22, 7, 871]\n  Val per-class acc=[0.013100436888635159, 0.004524887073785067, 0.9755555391311646]\n  New best (0.4922) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=1.1819 acc=0.3276 | Val loss=1.1084 acc=0.2522\n  Val true counts=[229, 221, 450] pred counts=[898, 0, 2]\n  Val per-class acc=[0.9912663698196411, 0.0, 0.0]\nEpoch 003/200 | Train loss=1.1454 acc=0.3353 | Val loss=1.0846 acc=0.4700\n  Val true counts=[229, 221, 450] pred counts=[81, 4, 815]\n  Val per-class acc=[0.061135370284318924, 0.0, 0.9088888764381409]\nEpoch 004/200 | Train loss=1.1326 acc=0.3282 | Val loss=1.0924 acc=0.3822\n  Val true counts=[229, 221, 450] pred counts=[3, 455, 442]\n  Val per-class acc=[0.0, 0.5203620195388794, 0.5088889002799988]\nEpoch 005/200 | Train loss=1.1239 acc=0.3444 | Val loss=1.0881 acc=0.4422\n  Val true counts=[229, 221, 450] pred counts=[3, 210, 687]\n  Val per-class acc=[0.0, 0.22624434530735016, 0.7733333110809326]\nEpoch 006/200 | Train loss=1.1183 acc=0.3265 | Val loss=1.0938 acc=0.3344\n  Val true counts=[229, 221, 450] pred counts=[618, 0, 282]\n  Val per-class acc=[0.6899563074111938, 0.0, 0.3177777826786041]\nEpoch 007/200 | Train loss=1.1101 acc=0.3345 | Val loss=1.0982 acc=0.3433\n  Val true counts=[229, 221, 450] pred counts=[56, 517, 327]\n  Val per-class acc=[0.06550218164920807, 0.570135772228241, 0.3733333349227905]\nEpoch 008/200 | Train loss=1.1043 acc=0.3356 | Val loss=1.0919 acc=0.3522\n  Val true counts=[229, 221, 450] pred counts=[0, 521, 379]\n  Val per-class acc=[0.0, 0.5610859990119934, 0.42888888716697693]\nEpoch 009/200 | Train loss=1.1032 acc=0.3402 | Val loss=1.0895 acc=0.2956\n  Val true counts=[229, 221, 450] pred counts=[0, 710, 190]\n  Val per-class acc=[0.0, 0.7873303294181824, 0.20444443821907043]\nEpoch 010/200 | Train loss=1.1046 acc=0.3279 | Val loss=1.1101 acc=0.2378\n  Val true counts=[229, 221, 450] pred counts=[419, 480, 1]\n  Val per-class acc=[0.4585152864456177, 0.49321267008781433, 0.0]\nEpoch 011/200 | Train loss=1.1022 acc=0.3387 | Val loss=1.0870 acc=0.4856\n  Val true counts=[229, 221, 450] pred counts=[0, 60, 840]\n  Val per-class acc=[0.0, 0.07692307978868484, 0.9333333373069763]\nEpoch 012/200 | Train loss=1.1038 acc=0.3319 | Val loss=1.0856 acc=0.4944\n  Val true counts=[229, 221, 450] pred counts=[0, 13, 887]\n  Val per-class acc=[0.0, 0.013574660755693913, 0.9822221994400024]\n  New best (0.4944) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 013/200 | Train loss=1.1004 acc=0.3419 | Val loss=1.1052 acc=0.2511\n  Val true counts=[229, 221, 450] pred counts=[410, 467, 23]\n  Val per-class acc=[0.44541484117507935, 0.49321267008781433, 0.03333333507180214]\nEpoch 014/200 | Train loss=1.1028 acc=0.3239 | Val loss=1.0964 acc=0.3278\n  Val true counts=[229, 221, 450] pred counts=[585, 18, 297]\n  Val per-class acc=[0.6550218462944031, 0.013574660755693913, 0.31555554270744324]\nEpoch 015/200 | Train loss=1.1010 acc=0.3462 | Val loss=1.0885 acc=0.4878\n  Val true counts=[229, 221, 450] pred counts=[0, 17, 883]\n  Val per-class acc=[0.0, 0.004524887073785067, 0.9733333587646484]\nEpoch 016/200 | Train loss=1.1009 acc=0.3464 | Val loss=1.0923 acc=0.4744\n  Val true counts=[229, 221, 450] pred counts=[6, 87, 807]\n  Val per-class acc=[0.0043668122962117195, 0.09954751282930374, 0.897777795791626]\nEpoch 017/200 | Train loss=1.0994 acc=0.3385 | Val loss=1.0995 acc=0.3300\n  Val true counts=[229, 221, 450] pred counts=[126, 473, 301]\n  Val per-class acc=[0.16157205402851105, 0.5203620195388794, 0.3222222328186035]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/853981114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/853981114.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/853981114.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, force_no_grad)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     tokens_all = self.encoder(\n\u001b[0m\u001b[1;32m     90\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_patch_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, channel_names, return_patch_tokens, return_all_patch_tokens)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mchs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHANNEL_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_upper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# x is (B, N, P, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         y = self.model(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram/neural_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, input_channels, return_all_tokens, return_patch_tokens, return_all_patch_tokens)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram/neural_transformer_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_attention, return_qkv)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mx_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mx_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_attn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram/neural_transformer_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_attention, return_qkv)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mqkv_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_bias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             qkv_bias = torch.cat((\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        if self.pooling == \"cls\":\n            raise ValueError(\"CLS pooling is handled in forward() using class token.\")\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def encode(self, x: torch.Tensor, force_no_grad: bool = False) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            def _encode_inner():\n                if self.pooling == \"cls\":\n                    # (B, N*P+1, E); index 0 is class token\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    return tokens_all[:, 0, :]\n\n                patch_tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n                return self._pool_tokens(patch_tokens)\n\n            if force_no_grad:\n                with torch.no_grad():\n                    pooled = _encode_inner()\n            else:\n                pooled = _encode_inner()\n        else:\n            with torch.no_grad():\n                if self.pooling == \"cls\":\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    pooled = tokens_all[:, 0, :]\n                else:\n                    patch_tokens = self.encoder(\n                        x, channel_names=self.channel_names, return_patch_tokens=True\n                    )\n                    pooled = self._pool_tokens(patch_tokens)\n\n        return pooled\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        pooled = self.encode(x)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nuse_binary_t1_t2 = True\n\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\nX_val = np.asarray(X_val)\ny_val = np.asarray(y_val)\n\nif use_binary_t1_t2:\n    # Keep only T1/T2 classes (commonly encoded as 0/1 in this pipeline).\n    # If upstream encoding differs, remap the two retained class ids to {0, 1}.\n    candidate_labels = [0, 1]\n    train_mask = np.isin(y_train, candidate_labels)\n    val_mask = np.isin(y_val, candidate_labels)\n\n    X_train = X_train[train_mask]\n    y_train = y_train[train_mask]\n    X_val = X_val[val_mask]\n    y_val = y_val[val_mask]\n\n    kept_labels = sorted(set(y_train.tolist()) | set(y_val.tolist()))\n    label_remap = {old: new for new, old in enumerate(kept_labels)}\n    y_train = np.array([label_remap[int(v)] for v in y_train], dtype=np.int64)\n    y_val = np.array([label_remap[int(v)] for v in y_val], dtype=np.int64)\n\n    num_classes = 2\n    print(\n        f\"  Binary mode enabled (T1/T2 only). \"\n        f\"Kept labels={kept_labels}, remap={label_remap}\"\n    )\nelse:\n    num_classes = int(config[\"model\"][\"num_classes\"])\n\ndef zscore_epochs(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n    # Per-epoch, per-channel normalization over time.\n    mu = X.mean(axis=-1, keepdims=True)\n    sd = X.std(axis=-1, keepdims=True)\n    return (X - mu) / (sd + eps)\n\nX_train = zscore_epochs(X_train)\nX_val = zscore_epochs(X_val)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = False\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\npooling_mode = \"cls\"\nunfreeze_last_n_blocks = 2\nhead_lr = 5e-5\nencoder_lr = 5e-6\nweight_decay = 1e-4\nprint(\n    f\"  Overrides | pooling={pooling_mode} \"\n    f\"unfreeze_last_n_blocks={unfreeze_last_n_blocks} \"\n    f\"head_lr={head_lr} encoder_lr={encoder_lr}\"\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=num_classes,\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    unfreeze_last_n_blocks=unfreeze_last_n_blocks,\n    pooling=pooling_mode,\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ndef run_linear_probe_sanity(\n    model: LaBraMProbe,\n    X_train_t: torch.Tensor,\n    y_train_t: torch.Tensor,\n    X_val_t: torch.Tensor,\n    y_val_t: torch.Tensor,\n    num_classes: int,\n    device: str,\n    batch_size: int = 256,\n    epochs: int = 25,\n    lr: float = 1e-2,\n):\n    print(\"\\n[Sanity] Running frozen-embedding linear probe...\")\n\n    def extract_features(X_tensor: torch.Tensor) -> torch.Tensor:\n        feat_loader = DataLoader(\n            TensorDataset(X_tensor), batch_size=batch_size, shuffle=False\n        )\n        features = []\n        model.eval()\n        with torch.no_grad():\n            for (x_batch,) in feat_loader:\n                x_batch = x_batch.to(device)\n                pooled = model.encode(x_batch, force_no_grad=True)\n                features.append(pooled.cpu())\n        return torch.cat(features, dim=0)\n\n    train_features = extract_features(X_train_t)\n    val_features = extract_features(X_val_t)\n    print(\n        f\"[Sanity] Feature shapes train={tuple(train_features.shape)} \"\n        f\"val={tuple(val_features.shape)}\"\n    )\n\n    linear_head = nn.Linear(train_features.shape[1], num_classes).to(device)\n    sanity_optimizer = optim.AdamW(linear_head.parameters(), lr=lr)\n    sanity_criterion = nn.CrossEntropyLoss()\n\n    sanity_train_loader = DataLoader(\n        TensorDataset(train_features, y_train_t), batch_size=batch_size, shuffle=True\n    )\n    sanity_val_loader = DataLoader(\n        TensorDataset(val_features, y_val_t), batch_size=batch_size, shuffle=False\n    )\n\n    best_val_acc = 0.0\n    for ep in range(1, epochs + 1):\n        linear_head.train()\n        train_correct = 0\n        train_total = 0\n        train_losses = []\n        for feat_batch, y_batch in sanity_train_loader:\n            feat_batch = feat_batch.to(device)\n            y_batch = y_batch.to(device)\n            sanity_optimizer.zero_grad()\n            logits = linear_head(feat_batch)\n            loss = sanity_criterion(logits, y_batch)\n            loss.backward()\n            sanity_optimizer.step()\n\n            preds = logits.argmax(1)\n            train_correct += (preds == y_batch).sum().item()\n            train_total += y_batch.numel()\n            train_losses.append(loss.item())\n\n        linear_head.eval()\n        val_correct = 0\n        val_total = 0\n        all_val_preds = []\n        all_val_targets = []\n        with torch.no_grad():\n            for feat_batch, y_batch in sanity_val_loader:\n                feat_batch = feat_batch.to(device)\n                y_batch = y_batch.to(device)\n                logits = linear_head(feat_batch)\n                preds = logits.argmax(1)\n                val_correct += (preds == y_batch).sum().item()\n                val_total += y_batch.numel()\n                all_val_preds.append(preds.cpu())\n                all_val_targets.append(y_batch.cpu())\n\n        train_acc = train_correct / max(train_total, 1)\n        val_acc = val_correct / max(val_total, 1)\n        best_val_acc = max(best_val_acc, val_acc)\n\n        if ep == 1 or ep % 5 == 0 or ep == epochs:\n            val_preds_flat = torch.cat(all_val_preds)\n            val_targets_flat = torch.cat(all_val_targets)\n            val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n            val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n            print(\n                f\"[Sanity] Epoch {ep:02d}/{epochs} \"\n                f\"train_loss={np.mean(train_losses):.4f} \"\n                f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n            )\n            print(\n                f\"[Sanity] Val true counts={val_true_counts.tolist()} \"\n                f\"pred counts={val_pred_counts.tolist()}\"\n            )\n\n    print(f\"[Sanity] Best val acc: {best_val_acc:.4f}\\n\")\n\n\nrun_linear_sanity_check = True\nif run_linear_sanity_check:\n    run_linear_probe_sanity(\n        model=model,\n        X_train_t=X_train_t,\n        y_train_t=y_train_t,\n        X_val_t=X_val_t,\n        y_val_t=y_val_t,\n        num_classes=num_classes,\n        device=device,\n        batch_size=batch_size,\n        epochs=25,\n        lr=1e-2,\n    )\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(weight=ce_weights)\nelse:\n    criterion = nn.CrossEntropyLoss()\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model.unfreeze_last_n_blocks})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:15:18.928592Z","iopub.execute_input":"2026-02-28T06:15:18.929191Z","iopub.status.idle":"2026-02-28T06:22:43.882968Z","shell.execute_reply.started":"2026-02-28T06:15:18.929159Z","shell.execute_reply":"2026-02-28T06:22:43.881905Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Binary mode enabled (T1/T2 only). Kept labels=[0, 1], remap={0: 0, 1: 1}\n  Train class counts: [884.0, 871.0]\n  Val class counts:   [229.0, 221.0]\n  Overrides | pooling=cls unfreeze_last_n_blocks=2 head_lr=5e-05 encoder_lr=5e-06\n\n  Device: cuda\n\n[Sanity] Running frozen-embedding linear probe...\n[Sanity] Feature shapes train=(1755, 200) val=(450, 200)\n[Sanity] Epoch 01/25 train_loss=0.8681 train_acc=0.5225 val_acc=0.5067\n[Sanity] Val true counts=[229, 221] pred counts=[449, 1]\n[Sanity] Epoch 05/25 train_loss=0.8145 train_acc=0.4957 val_acc=0.5089\n[Sanity] Val true counts=[229, 221] pred counts=[450, 0]\n[Sanity] Epoch 10/25 train_loss=0.7405 train_acc=0.5111 val_acc=0.5089\n[Sanity] Val true counts=[229, 221] pred counts=[450, 0]\n[Sanity] Epoch 15/25 train_loss=0.7466 train_acc=0.5436 val_acc=0.5067\n[Sanity] Val true counts=[229, 221] pred counts=[407, 43]\n[Sanity] Epoch 20/25 train_loss=0.8637 train_acc=0.5185 val_acc=0.4822\n[Sanity] Val true counts=[229, 221] pred counts=[74, 376]\n[Sanity] Epoch 25/25 train_loss=0.7970 train_acc=0.5088 val_acc=0.5267\n[Sanity] Val true counts=[229, 221] pred counts=[282, 168]\n[Sanity] Best val acc: 0.5311\n\n  Trainable params | head=51,970 encoder=966,160 (unfreeze_last_n_blocks=2)\n  Optimizer LRs | head=5e-05 encoder=5e-06 weight_decay=0.0001\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=0.9218 acc=0.4786 | Val loss=0.6927 acc=0.5044\n  Val true counts=[229, 221] pred counts=[428, 22]\n  Val per-class acc=[0.9475982785224915, 0.04524886980652809]\n  New best (0.5044) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=0.8086 acc=0.4883 | Val loss=0.6951 acc=0.4933\n  Val true counts=[229, 221] pred counts=[7, 443]\n  Val per-class acc=[0.017467249184846878, 0.9864253401756287]\nEpoch 003/200 | Train loss=0.7776 acc=0.4923 | Val loss=0.6930 acc=0.5022\n  Val true counts=[229, 221] pred counts=[399, 51]\n  Val per-class acc=[0.8820960521697998, 0.1085972860455513]\nEpoch 004/200 | Train loss=0.7551 acc=0.5197 | Val loss=0.6947 acc=0.5089\n  Val true counts=[229, 221] pred counts=[448, 2]\n  Val per-class acc=[0.9956331849098206, 0.004524887073785067]\n  New best (0.5089) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 005/200 | Train loss=0.7751 acc=0.4957 | Val loss=0.6922 acc=0.5022\n  Val true counts=[229, 221] pred counts=[353, 97]\n  Val per-class acc=[0.7816593647003174, 0.21266968548297882]\nEpoch 006/200 | Train loss=0.7465 acc=0.5179 | Val loss=0.6924 acc=0.4911\n  Val true counts=[229, 221] pred counts=[346, 104]\n  Val per-class acc=[0.7554585337638855, 0.2171945720911026]\nEpoch 007/200 | Train loss=0.7454 acc=0.5037 | Val loss=0.6933 acc=0.5067\n  Val true counts=[229, 221] pred counts=[441, 9]\n  Val per-class acc=[0.9781659245491028, 0.018099548295140266]\nEpoch 008/200 | Train loss=0.7352 acc=0.5014 | Val loss=0.6929 acc=0.5089\n  Val true counts=[229, 221] pred counts=[442, 8]\n  Val per-class acc=[0.9825327396392822, 0.018099548295140266]\nEpoch 009/200 | Train loss=0.7301 acc=0.5031 | Val loss=0.6930 acc=0.4956\n  Val true counts=[229, 221] pred counts=[90, 360]\n  Val per-class acc=[0.20087336003780365, 0.8009049892425537]\nEpoch 010/200 | Train loss=0.7201 acc=0.5054 | Val loss=0.6928 acc=0.5089\n  Val true counts=[229, 221] pred counts=[134, 316]\n  Val per-class acc=[0.31004366278648376, 0.7149321436882019]\nEpoch 011/200 | Train loss=0.7300 acc=0.4855 | Val loss=0.6940 acc=0.4667\n  Val true counts=[229, 221] pred counts=[33, 417]\n  Val per-class acc=[0.04803493618965149, 0.9004524946212769]\nEpoch 012/200 | Train loss=0.7196 acc=0.4934 | Val loss=0.6929 acc=0.5089\n  Val true counts=[229, 221] pred counts=[396, 54]\n  Val per-class acc=[0.8820960521697998, 0.12217194586992264]\nEpoch 013/200 | Train loss=0.7108 acc=0.5077 | Val loss=0.6976 acc=0.4911\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\nEpoch 014/200 | Train loss=0.7114 acc=0.5083 | Val loss=0.6930 acc=0.5289\n  Val true counts=[229, 221] pred counts=[363, 87]\n  Val per-class acc=[0.8296943306922913, 0.2171945720911026]\n  New best (0.5289) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 015/200 | Train loss=0.7124 acc=0.5077 | Val loss=0.6937 acc=0.4867\n  Val true counts=[229, 221] pred counts=[142, 308]\n  Val per-class acc=[0.3056768476963043, 0.6742081642150879]\nEpoch 016/200 | Train loss=0.7072 acc=0.4963 | Val loss=0.6930 acc=0.5067\n  Val true counts=[229, 221] pred counts=[217, 233]\n  Val per-class acc=[0.4890829622745514, 0.5248869061470032]\nEpoch 017/200 | Train loss=0.7004 acc=0.5168 | Val loss=0.6935 acc=0.5000\n  Val true counts=[229, 221] pred counts=[406, 44]\n  Val per-class acc=[0.8951964974403381, 0.09049773961305618]\nEpoch 018/200 | Train loss=0.6996 acc=0.5174 | Val loss=0.6935 acc=0.4978\n  Val true counts=[229, 221] pred counts=[215, 235]\n  Val per-class acc=[0.47598254680633545, 0.5203620195388794]\nEpoch 019/200 | Train loss=0.7050 acc=0.5043 | Val loss=0.6973 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 020/200 | Train loss=0.7039 acc=0.5083 | Val loss=0.6974 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 021/200 | Train loss=0.7009 acc=0.5140 | Val loss=0.6957 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 022/200 | Train loss=0.6979 acc=0.5088 | Val loss=0.6939 acc=0.4956\n  Val true counts=[229, 221] pred counts=[124, 326]\n  Val per-class acc=[0.2751091718673706, 0.7239819169044495]\nEpoch 023/200 | Train loss=0.6988 acc=0.5236 | Val loss=0.6933 acc=0.5111\n  Val true counts=[229, 221] pred counts=[335, 115]\n  Val per-class acc=[0.751091718673706, 0.2624434530735016]\nEpoch 024/200 | Train loss=0.7025 acc=0.4974 | Val loss=0.6959 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 025/200 | Train loss=0.7000 acc=0.5043 | Val loss=0.6931 acc=0.5089\n  Val true counts=[229, 221] pred counts=[338, 112]\n  Val per-class acc=[0.7554585337638855, 0.25339367985725403]\nEpoch 026/200 | Train loss=0.6936 acc=0.5259 | Val loss=0.6931 acc=0.5156\n  Val true counts=[229, 221] pred counts=[347, 103]\n  Val per-class acc=[0.7816593647003174, 0.2398190051317215]\nEpoch 027/200 | Train loss=0.6986 acc=0.4980 | Val loss=0.6931 acc=0.4778\n  Val true counts=[229, 221] pred counts=[160, 290]\n  Val per-class acc=[0.3362445533275604, 0.6244344115257263]\nEpoch 028/200 | Train loss=0.6957 acc=0.5225 | Val loss=0.6934 acc=0.5067\n  Val true counts=[229, 221] pred counts=[427, 23]\n  Val per-class acc=[0.9475982785224915, 0.04977375641465187]\nEpoch 029/200 | Train loss=0.6959 acc=0.5219 | Val loss=0.6942 acc=0.5044\n  Val true counts=[229, 221] pred counts=[446, 4]\n  Val per-class acc=[0.9868995547294617, 0.004524887073785067]\nEpoch 030/200 | Train loss=0.6951 acc=0.5162 | Val loss=0.6935 acc=0.5089\n  Val true counts=[229, 221] pred counts=[302, 148]\n  Val per-class acc=[0.6768559217453003, 0.33484163880348206]\nEpoch 031/200 | Train loss=0.6970 acc=0.5066 | Val loss=0.6932 acc=0.5222\n  Val true counts=[229, 221] pred counts=[250, 200]\n  Val per-class acc=[0.5764192342758179, 0.46606335043907166]\nEpoch 032/200 | Train loss=0.6991 acc=0.5020 | Val loss=0.6927 acc=0.5178\n  Val true counts=[229, 221] pred counts=[400, 50]\n  Val per-class acc=[0.8995633125305176, 0.12217194586992264]\nEpoch 033/200 | Train loss=0.6957 acc=0.5219 | Val loss=0.6948 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 034/200 | Train loss=0.7003 acc=0.4815 | Val loss=0.6925 acc=0.5333\n  Val true counts=[229, 221] pred counts=[335, 115]\n  Val per-class acc=[0.7729257345199585, 0.2850678861141205]\n  New best (0.5333) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 035/200 | Train loss=0.6959 acc=0.5123 | Val loss=0.6923 acc=0.5311\n  Val true counts=[229, 221] pred counts=[306, 144]\n  Val per-class acc=[0.7074235677719116, 0.3484162986278534]\nEpoch 036/200 | Train loss=0.6954 acc=0.5014 | Val loss=0.6928 acc=0.5311\n  Val true counts=[229, 221] pred counts=[272, 178]\n  Val per-class acc=[0.6331877708435059, 0.42533937096595764]\nEpoch 037/200 | Train loss=0.6932 acc=0.5094 | Val loss=0.6928 acc=0.5200\n  Val true counts=[229, 221] pred counts=[387, 63]\n  Val per-class acc=[0.8733624219894409, 0.1538461595773697]\nEpoch 038/200 | Train loss=0.6943 acc=0.5111 | Val loss=0.6937 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 039/200 | Train loss=0.6945 acc=0.5094 | Val loss=0.6933 acc=0.5222\n  Val true counts=[229, 221] pred counts=[312, 138]\n  Val per-class acc=[0.7117903828620911, 0.3257918655872345]\nEpoch 040/200 | Train loss=0.6946 acc=0.5145 | Val loss=0.6938 acc=0.4889\n  Val true counts=[229, 221] pred counts=[43, 407]\n  Val per-class acc=[0.09170305728912354, 0.9004524946212769]\nEpoch 041/200 | Train loss=0.6923 acc=0.5345 | Val loss=0.6936 acc=0.4933\n  Val true counts=[229, 221] pred counts=[53, 397]\n  Val per-class acc=[0.117903932929039, 0.8823529481887817]\nEpoch 042/200 | Train loss=0.6918 acc=0.5231 | Val loss=0.6949 acc=0.4911\n  Val true counts=[229, 221] pred counts=[2, 448]\n  Val per-class acc=[0.0043668122962117195, 0.9954751133918762]\nEpoch 043/200 | Train loss=0.6935 acc=0.5248 | Val loss=0.6926 acc=0.5311\n  Val true counts=[229, 221] pred counts=[294, 156]\n  Val per-class acc=[0.6812227368354797, 0.37556561827659607]\nEpoch 044/200 | Train loss=0.6966 acc=0.5123 | Val loss=0.6953 acc=0.4889\n  Val true counts=[229, 221] pred counts=[1, 449]\n  Val per-class acc=[0.0, 0.9954751133918762]\nEpoch 045/200 | Train loss=0.6925 acc=0.5174 | Val loss=0.6951 acc=0.4889\n  Val true counts=[229, 221] pred counts=[1, 449]\n  Val per-class acc=[0.0, 0.9954751133918762]\nEpoch 046/200 | Train loss=0.6952 acc=0.5026 | Val loss=0.6924 acc=0.5378\n  Val true counts=[229, 221] pred counts=[291, 159]\n  Val per-class acc=[0.6812227368354797, 0.3891402781009674]\n  New best (0.5378) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 047/200 | Train loss=0.6921 acc=0.5293 | Val loss=0.6943 acc=0.4933\n  Val true counts=[229, 221] pred counts=[5, 445]\n  Val per-class acc=[0.013100436888635159, 0.9909502267837524]\nEpoch 048/200 | Train loss=0.6925 acc=0.5242 | Val loss=0.6935 acc=0.4800\n  Val true counts=[229, 221] pred counts=[51, 399]\n  Val per-class acc=[0.10043668001890182, 0.8733031749725342]\nEpoch 049/200 | Train loss=0.6961 acc=0.5094 | Val loss=0.6937 acc=0.5000\n  Val true counts=[229, 221] pred counts=[32, 418]\n  Val per-class acc=[0.0786026194691658, 0.9366515874862671]\nEpoch 050/200 | Train loss=0.6922 acc=0.5276 | Val loss=0.6948 acc=0.4889\n  Val true counts=[229, 221] pred counts=[5, 445]\n  Val per-class acc=[0.008733624592423439, 0.9864253401756287]\nEpoch 051/200 | Train loss=0.6951 acc=0.5077 | Val loss=0.6933 acc=0.4933\n  Val true counts=[229, 221] pred counts=[337, 113]\n  Val per-class acc=[0.7379912734031677, 0.2398190051317215]\nEpoch 052/200 | Train loss=0.6948 acc=0.5157 | Val loss=0.6936 acc=0.5200\n  Val true counts=[229, 221] pred counts=[251, 199]\n  Val per-class acc=[0.5764192342758179, 0.4615384638309479]\nEpoch 053/200 | Train loss=0.6927 acc=0.5145 | Val loss=0.6935 acc=0.5044\n  Val true counts=[229, 221] pred counts=[196, 254]\n  Val per-class acc=[0.4410480260848999, 0.570135772228241]\nEpoch 054/200 | Train loss=0.6903 acc=0.5385 | Val loss=0.6932 acc=0.5133\n  Val true counts=[229, 221] pred counts=[382, 68]\n  Val per-class acc=[0.8558952212333679, 0.15837104618549347]\nEpoch 055/200 | Train loss=0.6911 acc=0.5219 | Val loss=0.6934 acc=0.5267\n  Val true counts=[229, 221] pred counts=[336, 114]\n  Val per-class acc=[0.7685589790344238, 0.2760181128978729]\nEpoch 056/200 | Train loss=0.6908 acc=0.5316 | Val loss=0.6933 acc=0.5000\n  Val true counts=[229, 221] pred counts=[184, 266]\n  Val per-class acc=[0.4104803502559662, 0.5927602052688599]\nEpoch 057/200 | Train loss=0.6923 acc=0.5185 | Val loss=0.6937 acc=0.5044\n  Val true counts=[229, 221] pred counts=[134, 316]\n  Val per-class acc=[0.3056768476963043, 0.7104072570800781]\nEpoch 058/200 | Train loss=0.6892 acc=0.5470 | Val loss=0.6932 acc=0.5311\n  Val true counts=[229, 221] pred counts=[348, 102]\n  Val per-class acc=[0.7991266250610352, 0.25339367985725403]\nEpoch 059/200 | Train loss=0.6917 acc=0.5231 | Val loss=0.6932 acc=0.5111\n  Val true counts=[229, 221] pred counts=[139, 311]\n  Val per-class acc=[0.3231441080570221, 0.7058823704719543]\nEpoch 060/200 | Train loss=0.6924 acc=0.5276 | Val loss=0.6926 acc=0.5222\n  Val true counts=[229, 221] pred counts=[344, 106]\n  Val per-class acc=[0.7816593647003174, 0.25339367985725403]\nEpoch 061/200 | Train loss=0.6929 acc=0.5174 | Val loss=0.6940 acc=0.5111\n  Val true counts=[229, 221] pred counts=[449, 1]\n  Val per-class acc=[1.0, 0.004524887073785067]\nEpoch 062/200 | Train loss=0.6922 acc=0.5225 | Val loss=0.6950 acc=0.4867\n  Val true counts=[229, 221] pred counts=[14, 436]\n  Val per-class acc=[0.026200873777270317, 0.9638009071350098]\nEpoch 063/200 | Train loss=0.6907 acc=0.5425 | Val loss=0.6941 acc=0.4978\n  Val true counts=[229, 221] pred counts=[49, 401]\n  Val per-class acc=[0.11353711783885956, 0.8959276080131531]\nEpoch 064/200 | Train loss=0.6913 acc=0.5345 | Val loss=0.6930 acc=0.5089\n  Val true counts=[229, 221] pred counts=[392, 58]\n  Val per-class acc=[0.8733624219894409, 0.1312217265367508]\nEpoch 065/200 | Train loss=0.6910 acc=0.5288 | Val loss=0.6929 acc=0.5133\n  Val true counts=[229, 221] pred counts=[420, 30]\n  Val per-class acc=[0.9388646483421326, 0.07239819318056107]\nEpoch 066/200 | Train loss=0.6908 acc=0.5379 | Val loss=0.6940 acc=0.5089\n  Val true counts=[229, 221] pred counts=[448, 2]\n  Val per-class acc=[0.9956331849098206, 0.004524887073785067]\nEpoch 067/200 | Train loss=0.6924 acc=0.5151 | Val loss=0.6956 acc=0.4911\n  Val true counts=[229, 221] pred counts=[10, 440]\n  Val per-class acc=[0.021834060549736023, 0.9773755669593811]\nEpoch 068/200 | Train loss=0.6870 acc=0.5373 | Val loss=0.6931 acc=0.5333\n  Val true counts=[229, 221] pred counts=[299, 151]\n  Val per-class acc=[0.6943231225013733, 0.3665158450603485]\nEpoch 069/200 | Train loss=0.6899 acc=0.5276 | Val loss=0.6946 acc=0.4956\n  Val true counts=[229, 221] pred counts=[50, 400]\n  Val per-class acc=[0.11353711783885956, 0.8914027214050293]\nEpoch 070/200 | Train loss=0.6933 acc=0.5140 | Val loss=0.6960 acc=0.4889\n  Val true counts=[229, 221] pred counts=[9, 441]\n  Val per-class acc=[0.017467249184846878, 0.9773755669593811]\nEpoch 071/200 | Train loss=0.6909 acc=0.5288 | Val loss=0.6942 acc=0.4933\n  Val true counts=[229, 221] pred counts=[59, 391]\n  Val per-class acc=[0.13100436329841614, 0.8687782883644104]\nEpoch 072/200 | Train loss=0.6873 acc=0.5476 | Val loss=0.6930 acc=0.5333\n  Val true counts=[229, 221] pred counts=[211, 239]\n  Val per-class acc=[0.5021833777427673, 0.5656108856201172]\nEpoch 073/200 | Train loss=0.6866 acc=0.5425 | Val loss=0.6943 acc=0.4956\n  Val true counts=[229, 221] pred counts=[66, 384]\n  Val per-class acc=[0.14847160875797272, 0.8552036285400391]\nEpoch 074/200 | Train loss=0.6890 acc=0.5476 | Val loss=0.6933 acc=0.5400\n  Val true counts=[229, 221] pred counts=[248, 202]\n  Val per-class acc=[0.5895196795463562, 0.48868778347969055]\n  New best (0.5400) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 075/200 | Train loss=0.6877 acc=0.5447 | Val loss=0.6933 acc=0.5333\n  Val true counts=[229, 221] pred counts=[247, 203]\n  Val per-class acc=[0.5807860493659973, 0.4841628968715668]\nEpoch 076/200 | Train loss=0.6878 acc=0.5504 | Val loss=0.6933 acc=0.5378\n  Val true counts=[229, 221] pred counts=[317, 133]\n  Val per-class acc=[0.7379912734031677, 0.3303167521953583]\nEpoch 077/200 | Train loss=0.6904 acc=0.5225 | Val loss=0.6938 acc=0.5000\n  Val true counts=[229, 221] pred counts=[124, 326]\n  Val per-class acc=[0.27947598695755005, 0.7285068035125732]\nEpoch 078/200 | Train loss=0.6864 acc=0.5658 | Val loss=0.6961 acc=0.5067\n  Val true counts=[229, 221] pred counts=[447, 3]\n  Val per-class acc=[0.9912663698196411, 0.004524887073785067]\nEpoch 079/200 | Train loss=0.6904 acc=0.5430 | Val loss=0.6934 acc=0.5111\n  Val true counts=[229, 221] pred counts=[375, 75]\n  Val per-class acc=[0.8384279608726501, 0.1719457060098648]\nEpoch 080/200 | Train loss=0.6861 acc=0.5487 | Val loss=0.6937 acc=0.5200\n  Val true counts=[229, 221] pred counts=[187, 263]\n  Val per-class acc=[0.43668121099472046, 0.6063348650932312]\nEpoch 081/200 | Train loss=0.6877 acc=0.5453 | Val loss=0.6960 acc=0.5044\n  Val true counts=[229, 221] pred counts=[42, 408]\n  Val per-class acc=[0.10480349510908127, 0.918552041053772]\nEpoch 082/200 | Train loss=0.6854 acc=0.5538 | Val loss=0.6936 acc=0.5311\n  Val true counts=[229, 221] pred counts=[238, 212]\n  Val per-class acc=[0.5589519739151001, 0.5022624731063843]\nEpoch 083/200 | Train loss=0.6863 acc=0.5419 | Val loss=0.6961 acc=0.5089\n  Val true counts=[229, 221] pred counts=[436, 14]\n  Val per-class acc=[0.9694322943687439, 0.031674209982156754]\nEpoch 084/200 | Train loss=0.6858 acc=0.5618 | Val loss=0.6938 acc=0.5244\n  Val true counts=[229, 221] pred counts=[201, 249]\n  Val per-class acc=[0.471615731716156, 0.5791855454444885]\nEpoch 085/200 | Train loss=0.6864 acc=0.5425 | Val loss=0.6942 acc=0.5200\n  Val true counts=[229, 221] pred counts=[347, 103]\n  Val per-class acc=[0.7860261797904968, 0.24434389173984528]\nEpoch 086/200 | Train loss=0.6826 acc=0.5789 | Val loss=0.6941 acc=0.5333\n  Val true counts=[229, 221] pred counts=[239, 211]\n  Val per-class acc=[0.5633187890052795, 0.5022624731063843]\nEpoch 087/200 | Train loss=0.6840 acc=0.5721 | Val loss=0.6954 acc=0.4956\n  Val true counts=[229, 221] pred counts=[124, 326]\n  Val per-class acc=[0.2751091718673706, 0.7239819169044495]\nEpoch 088/200 | Train loss=0.6839 acc=0.5533 | Val loss=0.6968 acc=0.4911\n  Val true counts=[229, 221] pred counts=[78, 372]\n  Val per-class acc=[0.17030568420886993, 0.8235294222831726]\nEpoch 089/200 | Train loss=0.6827 acc=0.5635 | Val loss=0.6945 acc=0.5356\n  Val true counts=[229, 221] pred counts=[294, 156]\n  Val per-class acc=[0.6855894923210144, 0.38009050488471985]\nEpoch 090/200 | Train loss=0.6805 acc=0.5880 | Val loss=0.6944 acc=0.5289\n  Val true counts=[229, 221] pred counts=[267, 183]\n  Val per-class acc=[0.6200873255729675, 0.4343891441822052]\nEpoch 091/200 | Train loss=0.6784 acc=0.5772 | Val loss=0.6971 acc=0.5044\n  Val true counts=[229, 221] pred counts=[404, 46]\n  Val per-class acc=[0.8951964974403381, 0.09954751282930374]\nEpoch 092/200 | Train loss=0.6801 acc=0.5806 | Val loss=0.6958 acc=0.5178\n  Val true counts=[229, 221] pred counts=[346, 104]\n  Val per-class acc=[0.7816593647003174, 0.24434389173984528]\nEpoch 093/200 | Train loss=0.6810 acc=0.5652 | Val loss=0.7017 acc=0.5022\n  Val true counts=[229, 221] pred counts=[37, 413]\n  Val per-class acc=[0.09170305728912354, 0.9276018142700195]\nEpoch 094/200 | Train loss=0.6779 acc=0.5692 | Val loss=0.6965 acc=0.5000\n  Val true counts=[229, 221] pred counts=[162, 288]\n  Val per-class acc=[0.3624454140663147, 0.6425339579582214]\nEpoch 095/200 | Train loss=0.6826 acc=0.5647 | Val loss=0.6982 acc=0.5000\n  Val true counts=[229, 221] pred counts=[392, 58]\n  Val per-class acc=[0.864628791809082, 0.12217194586992264]\nEpoch 096/200 | Train loss=0.6761 acc=0.5806 | Val loss=0.6961 acc=0.5311\n  Val true counts=[229, 221] pred counts=[292, 158]\n  Val per-class acc=[0.6768559217453003, 0.38009050488471985]\nEpoch 097/200 | Train loss=0.6776 acc=0.5829 | Val loss=0.6964 acc=0.5311\n  Val true counts=[229, 221] pred counts=[234, 216]\n  Val per-class acc=[0.5502183437347412, 0.5113122463226318]\nEpoch 098/200 | Train loss=0.6763 acc=0.5755 | Val loss=0.7002 acc=0.5067\n  Val true counts=[229, 221] pred counts=[381, 69]\n  Val per-class acc=[0.847161591053009, 0.1538461595773697]\nEpoch 099/200 | Train loss=0.6752 acc=0.5880 | Val loss=0.6982 acc=0.5022\n  Val true counts=[229, 221] pred counts=[175, 275]\n  Val per-class acc=[0.3930130898952484, 0.6153846383094788]\nEpoch 100/200 | Train loss=0.6773 acc=0.5778 | Val loss=0.7014 acc=0.5133\n  Val true counts=[229, 221] pred counts=[368, 82]\n  Val per-class acc=[0.8253275156021118, 0.19004525244235992]\nEpoch 101/200 | Train loss=0.6776 acc=0.5652 | Val loss=0.7001 acc=0.5244\n  Val true counts=[229, 221] pred counts=[339, 111]\n  Val per-class acc=[0.7729257345199585, 0.26696833968162537]\nEpoch 102/200 | Train loss=0.6745 acc=0.5778 | Val loss=0.7022 acc=0.4933\n  Val true counts=[229, 221] pred counts=[119, 331]\n  Val per-class acc=[0.2620087265968323, 0.733031690120697]\nEpoch 103/200 | Train loss=0.6709 acc=0.5949 | Val loss=0.6998 acc=0.5089\n  Val true counts=[229, 221] pred counts=[274, 176]\n  Val per-class acc=[0.6157205104827881, 0.39819005131721497]\nEpoch 104/200 | Train loss=0.6651 acc=0.5983 | Val loss=0.7045 acc=0.4933\n  Val true counts=[229, 221] pred counts=[117, 333]\n  Val per-class acc=[0.25764191150665283, 0.7375565767288208]\nEpoch 105/200 | Train loss=0.6696 acc=0.6063 | Val loss=0.7010 acc=0.5311\n  Val true counts=[229, 221] pred counts=[254, 196]\n  Val per-class acc=[0.5938864350318909, 0.46606335043907166]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1003497584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1003497584.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1003497584.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, force_no_grad)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1003497584.py\u001b[0m in \u001b[0;36m_encode_inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0;31m# (B, N*P+1, E); index 0 is class token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     tokens_all = self.encoder(\n\u001b[0m\u001b[1;32m     72\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_patch_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, channel_names, return_patch_tokens, return_all_patch_tokens)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mchs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHANNEL_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_upper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# x is (B, N, P, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         y = self.model(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram/neural_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, input_channels, return_all_tokens, return_patch_tokens, return_all_patch_tokens)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/labram/neural_transformer_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_attention, return_qkv)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_mlp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx_mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/eeg/layers/drop_path.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# (B, 1, 1, 1, ...) mask broadcast along non-batch dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrandom_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbinary_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbinary_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"\"\"\"Train LaBraM probe and save the best checkpoint.\"\"\"\n\nfrom eeg.layers.labram_encoder import LaBraMEncoder\nfrom torch.utils.data import WeightedRandomSampler\n\n# from models.labram_probe import LaBraMProbe\n\nclass LaBraMProbe(nn.Module):\n    def __init__(\n        self,\n        checkpoint_path: str | Path,\n        channel_names: list[str],\n        num_classes: int = 3,\n        freeze_encoder: bool = True,\n        unfreeze_last_n_blocks: int = 2,\n        pooling: str = \"mean\",\n        hidden_dim: int = 256,\n        dropout: float = 0.3,\n    ) -> None:\n        super().__init__()\n\n        self.encoder = LaBraMEncoder.from_pretrained(str(checkpoint_path))\n        self.channel_names = channel_names\n        self.pooling = pooling\n        self.freeze_encoder = freeze_encoder\n        self.unfreeze_last_n_blocks = max(0, int(unfreeze_last_n_blocks))\n\n        if freeze_encoder:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        if self.unfreeze_last_n_blocks > 0:\n            total_blocks = len(self.encoder.model.blocks)\n            n = min(self.unfreeze_last_n_blocks, total_blocks)\n            for block in self.encoder.model.blocks[-n:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n\n            # Keep encoder output scale adaptable when any encoder blocks are trainable.\n            for param in self.encoder.model.norm.parameters():\n                param.requires_grad = True\n\n        self.encoder_has_trainable_params = any(\n            p.requires_grad for p in self.encoder.parameters()\n        )\n\n        embed_dim = self.encoder.model.embed_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def _pool_tokens(self, tokens: torch.Tensor) -> torch.Tensor:\n        # tokens: (B, N, P, E)\n        if self.pooling == \"mean\":\n            return tokens.mean(dim=(1, 2))\n        if self.pooling == \"max\":\n            return tokens.amax(dim=(1, 2))\n        if self.pooling == \"cls\":\n            raise ValueError(\"CLS pooling is handled in forward() using class token.\")\n        raise ValueError(f\"Unsupported pooling method: {self.pooling}\")\n\n    def encode(self, x: torch.Tensor, force_no_grad: bool = False) -> torch.Tensor:\n        # x: (B, N, T)\n        if self.encoder_has_trainable_params:\n            def _encode_inner():\n                if self.pooling == \"cls\":\n                    # (B, N*P+1, E); index 0 is class token\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    return tokens_all[:, 0, :]\n\n                patch_tokens = self.encoder(\n                    x, channel_names=self.channel_names, return_patch_tokens=True\n                )\n                return self._pool_tokens(patch_tokens)\n\n            if force_no_grad:\n                with torch.no_grad():\n                    pooled = _encode_inner()\n            else:\n                pooled = _encode_inner()\n        else:\n            with torch.no_grad():\n                if self.pooling == \"cls\":\n                    tokens_all = self.encoder(\n                        x, channel_names=self.channel_names, return_all_patch_tokens=True\n                    )\n                    pooled = tokens_all[:, 0, :]\n                else:\n                    patch_tokens = self.encoder(\n                        x, channel_names=self.channel_names, return_patch_tokens=True\n                    )\n                    pooled = self._pool_tokens(patch_tokens)\n\n        return pooled\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        pooled = self.encode(x)\n        return self.classifier(pooled)\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING LaBraM PROBE\")\nprint(\"=\" * 60)\n\nuse_binary_t1_t2 = True\nuse_long_context_resample = True\ntarget_context_len = 1600\n\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\nX_val = np.asarray(X_val)\ny_val = np.asarray(y_val)\n\nif use_binary_t1_t2:\n    # Keep only T1/T2 classes (commonly encoded as 0/1 in this pipeline).\n    # If upstream encoding differs, remap the two retained class ids to {0, 1}.\n    candidate_labels = [0, 1]\n    train_mask = np.isin(y_train, candidate_labels)\n    val_mask = np.isin(y_val, candidate_labels)\n\n    X_train = X_train[train_mask]\n    y_train = y_train[train_mask]\n    X_val = X_val[val_mask]\n    y_val = y_val[val_mask]\n\n    kept_labels = sorted(set(y_train.tolist()) | set(y_val.tolist()))\n    label_remap = {old: new for new, old in enumerate(kept_labels)}\n    y_train = np.array([label_remap[int(v)] for v in y_train], dtype=np.int64)\n    y_val = np.array([label_remap[int(v)] for v in y_val], dtype=np.int64)\n\n    num_classes = 2\n    print(\n        f\"  Binary mode enabled (T1/T2 only). \"\n        f\"Kept labels={kept_labels}, remap={label_remap}\"\n    )\nelse:\n    num_classes = int(config[\"model\"][\"num_classes\"])\n\ndef resample_epochs_to_length(X: np.ndarray, target_len: int) -> np.ndarray:\n    # Resample each epoch/channel to fixed temporal length expected by LaBraM context.\n    if X.shape[-1] == target_len:\n        return X\n    n_epochs, n_channels, src_len = X.shape\n    x_old = np.linspace(0.0, 1.0, src_len, dtype=np.float32)\n    x_new = np.linspace(0.0, 1.0, target_len, dtype=np.float32)\n    X_out = np.empty((n_epochs, n_channels, target_len), dtype=np.float32)\n    for i in range(n_epochs):\n        for ch in range(n_channels):\n            X_out[i, ch] = np.interp(x_new, x_old, X[i, ch].astype(np.float32))\n    return X_out\n\ndef zscore_epochs(X: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n    # Per-epoch, per-channel normalization over time.\n    mu = X.mean(axis=-1, keepdims=True)\n    sd = X.std(axis=-1, keepdims=True)\n    return (X - mu) / (sd + eps)\n\nif use_long_context_resample:\n    X_train = resample_epochs_to_length(X_train, target_context_len)\n    X_val = resample_epochs_to_length(X_val, target_context_len)\n    print(\n        f\"  Long-context resample enabled. \"\n        f\"New sequence length={target_context_len}\"\n    )\n\nX_train = zscore_epochs(X_train)\nX_val = zscore_epochs(X_val)\n\nX_train_t = torch.FloatTensor(X_train)\ny_train_t = torch.LongTensor(y_train)\nX_val_t = torch.FloatTensor(X_val)\ny_val_t = torch.LongTensor(y_val)\n\nbatch_size = config[\"training\"][\"batch_size\"]\nassert y_train_t.min().item() >= 0 and y_train_t.max().item() < num_classes\nassert y_val_t.min().item() >= 0 and y_val_t.max().item() < num_classes\n\ntrain_class_counts = torch.bincount(y_train_t, minlength=num_classes).float()\nval_class_counts = torch.bincount(y_val_t, minlength=num_classes).float()\nprint(f\"  Train class counts: {train_class_counts.tolist()}\")\nprint(f\"  Val class counts:   {val_class_counts.tolist()}\")\n\n# IMPORTANT: Do not combine sampler + weighted CE unless intentionally testing.\nuse_weighted_sampler = False\nuse_class_weighted_loss = False\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\nval_dataset = TensorDataset(X_val_t, y_val_t)\n\nif use_weighted_sampler:\n    class_weights_for_sampler = 1.0 / train_class_counts.clamp(min=1)\n    sample_weights = class_weights_for_sampler[y_train_t]\n    assert len(sample_weights) == len(train_dataset), (\n        f\"Sample weights length {len(sample_weights)} != \"\n        f\"train dataset length {len(train_dataset)}\"\n    )\n    train_sampler = WeightedRandomSampler(\n        weights=sample_weights.double(),\n        num_samples=len(train_dataset),\n        replacement=True,\n    )\nelse:\n    train_sampler = None\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    sampler=train_sampler,\n    shuffle=not use_weighted_sampler,\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)\n\nmodel_cfg = config[\"model\"]\npooling_mode = \"cls\"\nunfreeze_last_n_blocks = 2\nhead_lr = 5e-5\nencoder_lr = 5e-6\nweight_decay = 1e-4\nlabel_smoothing = 0.05\nprint(\n    f\"  Overrides | pooling={pooling_mode} \"\n    f\"unfreeze_last_n_blocks={unfreeze_last_n_blocks} \"\n    f\"head_lr={head_lr} encoder_lr={encoder_lr} \"\n    f\"label_smoothing={label_smoothing}\"\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\n  Device: {device}\")\n\ncheckpoint_path = Path(model_cfg[\"checkpoint_path\"])\nif not checkpoint_path.is_absolute():\n    checkpoint_path = get_project_root() / checkpoint_path\n\nmodel = LaBraMProbe(\n    checkpoint_path=checkpoint_path,\n    channel_names=channel_names,\n    num_classes=num_classes,\n    freeze_encoder=model_cfg.get(\"freeze_encoder\", True),\n    unfreeze_last_n_blocks=unfreeze_last_n_blocks,\n    pooling=pooling_mode,\n    hidden_dim=model_cfg.get(\"hidden_dim\", 256),\n    dropout=model_cfg.get(\"dropout\", 0.3),\n)\n\nmodel.to(device)\n\ndef run_linear_probe_sanity(\n    model: LaBraMProbe,\n    X_train_t: torch.Tensor,\n    y_train_t: torch.Tensor,\n    X_val_t: torch.Tensor,\n    y_val_t: torch.Tensor,\n    num_classes: int,\n    device: str,\n    batch_size: int = 256,\n    epochs: int = 25,\n    lr: float = 1e-2,\n):\n    print(\"\\n[Sanity] Running frozen-embedding linear probe...\")\n\n    def extract_features(X_tensor: torch.Tensor) -> torch.Tensor:\n        feat_loader = DataLoader(\n            TensorDataset(X_tensor), batch_size=batch_size, shuffle=False\n        )\n        features = []\n        model.eval()\n        with torch.no_grad():\n            for (x_batch,) in feat_loader:\n                x_batch = x_batch.to(device)\n                pooled = model.encode(x_batch, force_no_grad=True)\n                features.append(pooled.cpu())\n        return torch.cat(features, dim=0)\n\n    train_features = extract_features(X_train_t)\n    val_features = extract_features(X_val_t)\n    print(\n        f\"[Sanity] Feature shapes train={tuple(train_features.shape)} \"\n        f\"val={tuple(val_features.shape)}\"\n    )\n\n    linear_head = nn.Linear(train_features.shape[1], num_classes).to(device)\n    sanity_optimizer = optim.AdamW(linear_head.parameters(), lr=lr)\n    sanity_criterion = nn.CrossEntropyLoss()\n\n    sanity_train_loader = DataLoader(\n        TensorDataset(train_features, y_train_t), batch_size=batch_size, shuffle=True\n    )\n    sanity_val_loader = DataLoader(\n        TensorDataset(val_features, y_val_t), batch_size=batch_size, shuffle=False\n    )\n\n    best_val_acc = 0.0\n    for ep in range(1, epochs + 1):\n        linear_head.train()\n        train_correct = 0\n        train_total = 0\n        train_losses = []\n        for feat_batch, y_batch in sanity_train_loader:\n            feat_batch = feat_batch.to(device)\n            y_batch = y_batch.to(device)\n            sanity_optimizer.zero_grad()\n            logits = linear_head(feat_batch)\n            loss = sanity_criterion(logits, y_batch)\n            loss.backward()\n            sanity_optimizer.step()\n\n            preds = logits.argmax(1)\n            train_correct += (preds == y_batch).sum().item()\n            train_total += y_batch.numel()\n            train_losses.append(loss.item())\n\n        linear_head.eval()\n        val_correct = 0\n        val_total = 0\n        all_val_preds = []\n        all_val_targets = []\n        with torch.no_grad():\n            for feat_batch, y_batch in sanity_val_loader:\n                feat_batch = feat_batch.to(device)\n                y_batch = y_batch.to(device)\n                logits = linear_head(feat_batch)\n                preds = logits.argmax(1)\n                val_correct += (preds == y_batch).sum().item()\n                val_total += y_batch.numel()\n                all_val_preds.append(preds.cpu())\n                all_val_targets.append(y_batch.cpu())\n\n        train_acc = train_correct / max(train_total, 1)\n        val_acc = val_correct / max(val_total, 1)\n        best_val_acc = max(best_val_acc, val_acc)\n\n        if ep == 1 or ep % 5 == 0 or ep == epochs:\n            val_preds_flat = torch.cat(all_val_preds)\n            val_targets_flat = torch.cat(all_val_targets)\n            val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n            val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n            print(\n                f\"[Sanity] Epoch {ep:02d}/{epochs} \"\n                f\"train_loss={np.mean(train_losses):.4f} \"\n                f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n            )\n            print(\n                f\"[Sanity] Val true counts={val_true_counts.tolist()} \"\n                f\"pred counts={val_pred_counts.tolist()}\"\n            )\n\n    print(f\"[Sanity] Best val acc: {best_val_acc:.4f}\\n\")\n\n\nrun_linear_sanity_check = True\nif run_linear_sanity_check:\n    run_linear_probe_sanity(\n        model=model,\n        X_train_t=X_train_t,\n        y_train_t=y_train_t,\n        X_val_t=X_val_t,\n        y_val_t=y_val_t,\n        num_classes=num_classes,\n        device=device,\n        batch_size=batch_size,\n        epochs=25,\n        lr=1e-2,\n    )\n\nif use_class_weighted_loss:\n    ce_weights = (len(y_train_t) / (num_classes * train_class_counts.clamp(min=1))).to(\n        device=device, dtype=torch.float32\n    )\n    criterion = nn.CrossEntropyLoss(\n        weight=ce_weights, label_smoothing=label_smoothing\n    )\nelse:\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n\nhead_params = [p for p in model.classifier.parameters() if p.requires_grad]\nencoder_params = [p for p in model.encoder.parameters() if p.requires_grad]\nif encoder_params:\n    optimizer = optim.AdamW(\n        [\n            {\"params\": head_params, \"lr\": head_lr},\n            {\"params\": encoder_params, \"lr\": encoder_lr},\n        ],\n        weight_decay=weight_decay,\n    )\nelse:\n    optimizer = optim.AdamW(head_params, lr=head_lr, weight_decay=weight_decay)\n\nnum_head_params = sum(p.numel() for p in head_params)\nnum_encoder_params = sum(p.numel() for p in encoder_params)\nprint(\n    f\"  Trainable params | head={num_head_params:,} \"\n    f\"encoder={num_encoder_params:,} \"\n    f\"(unfreeze_last_n_blocks={model.unfreeze_last_n_blocks})\"\n)\nif num_encoder_params > 0:\n    print(\n        f\"  Optimizer LRs | head={head_lr} encoder={encoder_lr} \"\n        f\"weight_decay={weight_decay}\"\n    )\nelse:\n    print(f\"  Optimizer LR  | head={head_lr} weight_decay={weight_decay}\")\n\n\n\n\n\nsave_path = (\n    get_project_root()\n    / config[\"training\"][\"savedir\"]\n    / config[\"training\"][\"savename\"]\n)\nos.makedirs(save_path.parent, exist_ok=True)\n\nbest_val_acc = 0.0\npatience_counter = 0\npatience = config[\"training\"][\"early_stopping_patience\"]\nnum_epochs = config[\"training\"][\"num_epochs\"]\n\nprint(f\"  Epochs: {num_epochs}  |  Early-stop patience: {patience}\\n\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_losses = []\n    train_correct = 0\n    train_total = 0\n    for X_batch, y_batch in train_loader:\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(X_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        preds = logits.argmax(1)\n        train_correct += (preds == y_batch).sum().item()\n        train_total += y_batch.numel()\n        train_losses.append(loss.item())\n\n    model.eval()\n    val_losses = []\n    val_correct = 0\n    val_total = 0\n    all_val_preds = []\n    all_val_targets = []\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(X_batch)\n            loss = criterion(logits, y_batch)\n\n            preds = logits.argmax(1)\n            val_correct += (preds == y_batch).sum().item()\n            val_total += y_batch.numel()\n            all_val_preds.append(preds.cpu())\n            all_val_targets.append(y_batch.cpu())\n\n            val_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n    train_acc = train_correct / max(train_total, 1)\n    val_loss = np.mean(val_losses)\n    val_acc = val_correct / max(val_total, 1)\n\n    val_preds_flat = torch.cat(all_val_preds) if all_val_preds else torch.empty(0, dtype=torch.long)\n    val_targets_flat = torch.cat(all_val_targets) if all_val_targets else torch.empty(0, dtype=torch.long)\n    val_pred_counts = torch.bincount(val_preds_flat, minlength=num_classes)\n    val_true_counts = torch.bincount(val_targets_flat, minlength=num_classes)\n\n    print(\n        f\"Epoch {epoch+1:03d}/{num_epochs} | \"\n        f\"Train loss={train_loss:.4f} acc={train_acc:.4f} | \"\n        f\"Val loss={val_loss:.4f} acc={val_acc:.4f}\"\n    )\n    print(\n        f\"  Val true counts={val_true_counts.tolist()} \"\n        f\"pred counts={val_pred_counts.tolist()}\"\n    )\n\n    # Track per-class accuracy to spot class collapse early.\n    per_class_acc = []\n    for c in range(num_classes):\n        class_mask = val_targets_flat == c\n        if class_mask.any():\n            class_acc = (val_preds_flat[class_mask] == c).float().mean().item()\n        else:\n            class_acc = float(\"nan\")\n        per_class_acc.append(class_acc)\n    print(f\"  Val per-class acc={per_class_acc}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save(\n            {\n                \"model_state_dict\": model.state_dict(),\n                \"config\": config,\n                \"best_val_acc\": best_val_acc,\n                \"channel_names\": channel_names,\n            },\n            str(save_path),\n        )\n        print(f\"  New best ({val_acc:.4f}) saved to {save_path}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}.\")\n            break\n\nprint(f\"\\nTraining complete. Best val acc: {best_val_acc:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:22:55.994895Z","iopub.execute_input":"2026-02-28T06:22:55.995558Z","iopub.status.idle":"2026-02-28T06:41:38.399185Z","shell.execute_reply.started":"2026-02-28T06:22:55.995527Z","shell.execute_reply":"2026-02-28T06:41:38.398527Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING LaBraM PROBE\n============================================================\n  Binary mode enabled (T1/T2 only). Kept labels=[0, 1], remap={0: 0, 1: 1}\n  Long-context resample enabled. New sequence length=1600\n  Train class counts: [884.0, 871.0]\n  Val class counts:   [229.0, 221.0]\n  Overrides | pooling=cls unfreeze_last_n_blocks=2 head_lr=5e-05 encoder_lr=5e-06 label_smoothing=0.05\n\n  Device: cuda\n\n[Sanity] Running frozen-embedding linear probe...\n[Sanity] Feature shapes train=(1755, 200) val=(450, 200)\n[Sanity] Epoch 01/25 train_loss=1.0085 train_acc=0.4877 val_acc=0.5089\n[Sanity] Val true counts=[229, 221] pred counts=[450, 0]\n[Sanity] Epoch 05/25 train_loss=0.8384 train_acc=0.5060 val_acc=0.4911\n[Sanity] Val true counts=[229, 221] pred counts=[0, 450]\n[Sanity] Epoch 10/25 train_loss=0.8344 train_acc=0.5088 val_acc=0.5200\n[Sanity] Val true counts=[229, 221] pred counts=[241, 209]\n[Sanity] Epoch 15/25 train_loss=0.8009 train_acc=0.5054 val_acc=0.5200\n[Sanity] Val true counts=[229, 221] pred counts=[73, 377]\n[Sanity] Epoch 20/25 train_loss=0.8380 train_acc=0.5145 val_acc=0.4911\n[Sanity] Val true counts=[229, 221] pred counts=[0, 450]\n[Sanity] Epoch 25/25 train_loss=0.7402 train_acc=0.5191 val_acc=0.5089\n[Sanity] Val true counts=[229, 221] pred counts=[450, 0]\n[Sanity] Best val acc: 0.5267\n\n  Trainable params | head=51,970 encoder=966,160 (unfreeze_last_n_blocks=2)\n  Optimizer LRs | head=5e-05 encoder=5e-06 weight_decay=0.0001\n  Epochs: 200  |  Early-stop patience: 40\n\nEpoch 001/200 | Train loss=0.8287 acc=0.4832 | Val loss=0.6948 acc=0.5111\n  Val true counts=[229, 221] pred counts=[447, 3]\n  Val per-class acc=[0.9956331849098206, 0.009049774147570133]\n  New best (0.5111) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 002/200 | Train loss=0.7857 acc=0.4963 | Val loss=0.6947 acc=0.5156\n  Val true counts=[229, 221] pred counts=[447, 3]\n  Val per-class acc=[1.0, 0.013574660755693913]\n  New best (0.5156) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 003/200 | Train loss=0.7706 acc=0.4934 | Val loss=0.6961 acc=0.4867\n  Val true counts=[229, 221] pred counts=[4, 446]\n  Val per-class acc=[0.0043668122962117195, 0.9864253401756287]\nEpoch 004/200 | Train loss=0.7488 acc=0.5322 | Val loss=0.7050 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 005/200 | Train loss=0.7497 acc=0.4923 | Val loss=0.6943 acc=0.5000\n  Val true counts=[229, 221] pred counts=[362, 88]\n  Val per-class acc=[0.7991266250610352, 0.19004525244235992]\nEpoch 006/200 | Train loss=0.7303 acc=0.5174 | Val loss=0.6982 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 007/200 | Train loss=0.7332 acc=0.4849 | Val loss=0.6939 acc=0.5022\n  Val true counts=[229, 221] pred counts=[403, 47]\n  Val per-class acc=[0.8908296823501587, 0.09954751282930374]\nEpoch 008/200 | Train loss=0.7267 acc=0.4912 | Val loss=0.6943 acc=0.5089\n  Val true counts=[229, 221] pred counts=[448, 2]\n  Val per-class acc=[0.9956331849098206, 0.004524887073785067]\nEpoch 009/200 | Train loss=0.7222 acc=0.4934 | Val loss=0.6935 acc=0.5044\n  Val true counts=[229, 221] pred counts=[274, 176]\n  Val per-class acc=[0.6113536953926086, 0.3936651647090912]\nEpoch 010/200 | Train loss=0.7219 acc=0.4826 | Val loss=0.6963 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 011/200 | Train loss=0.7121 acc=0.4986 | Val loss=0.7008 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 012/200 | Train loss=0.7052 acc=0.5020 | Val loss=0.6936 acc=0.5333\n  Val true counts=[229, 221] pred counts=[105, 345]\n  Val per-class acc=[0.27074235677719116, 0.8054298758506775]\n  New best (0.5333) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 013/200 | Train loss=0.7036 acc=0.5031 | Val loss=0.6933 acc=0.5200\n  Val true counts=[229, 221] pred counts=[313, 137]\n  Val per-class acc=[0.7117903828620911, 0.3212669789791107]\nEpoch 014/200 | Train loss=0.7005 acc=0.5117 | Val loss=0.7009 acc=0.4911\n  Val true counts=[229, 221] pred counts=[0, 450]\n  Val per-class acc=[0.0, 1.0]\nEpoch 015/200 | Train loss=0.7016 acc=0.5066 | Val loss=0.6939 acc=0.5067\n  Val true counts=[229, 221] pred counts=[443, 7]\n  Val per-class acc=[0.9825327396392822, 0.013574660755693913]\nEpoch 016/200 | Train loss=0.6975 acc=0.5174 | Val loss=0.7015 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 017/200 | Train loss=0.7003 acc=0.5145 | Val loss=0.6935 acc=0.5200\n  Val true counts=[229, 221] pred counts=[393, 57]\n  Val per-class acc=[0.8864628672599792, 0.14027149975299835]\nEpoch 018/200 | Train loss=0.7038 acc=0.4883 | Val loss=0.6937 acc=0.5022\n  Val true counts=[229, 221] pred counts=[345, 105]\n  Val per-class acc=[0.7641921639442444, 0.23076923191547394]\nEpoch 019/200 | Train loss=0.7018 acc=0.4963 | Val loss=0.6959 acc=0.5044\n  Val true counts=[229, 221] pred counts=[444, 6]\n  Val per-class acc=[0.9825327396392822, 0.009049774147570133]\nEpoch 020/200 | Train loss=0.6976 acc=0.5083 | Val loss=0.6948 acc=0.5111\n  Val true counts=[229, 221] pred counts=[173, 277]\n  Val per-class acc=[0.39737990498542786, 0.6289592981338501]\nEpoch 021/200 | Train loss=0.6986 acc=0.5100 | Val loss=0.6955 acc=0.5044\n  Val true counts=[229, 221] pred counts=[420, 30]\n  Val per-class acc=[0.9301310181617737, 0.06334841996431351]\nEpoch 022/200 | Train loss=0.6948 acc=0.5276 | Val loss=0.6962 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 023/200 | Train loss=0.6978 acc=0.5037 | Val loss=0.6944 acc=0.5022\n  Val true counts=[229, 221] pred counts=[427, 23]\n  Val per-class acc=[0.943231463432312, 0.04524886980652809]\nEpoch 024/200 | Train loss=0.6985 acc=0.4946 | Val loss=0.6970 acc=0.5089\n  Val true counts=[229, 221] pred counts=[450, 0]\n  Val per-class acc=[1.0, 0.0]\nEpoch 025/200 | Train loss=0.6994 acc=0.5054 | Val loss=0.6940 acc=0.5067\n  Val true counts=[229, 221] pred counts=[413, 37]\n  Val per-class acc=[0.9170305728912354, 0.08144796639680862]\nEpoch 026/200 | Train loss=0.6985 acc=0.4969 | Val loss=0.6937 acc=0.5200\n  Val true counts=[229, 221] pred counts=[247, 203]\n  Val per-class acc=[0.567685604095459, 0.47058823704719543]\nEpoch 027/200 | Train loss=0.6942 acc=0.5208 | Val loss=0.6946 acc=0.5067\n  Val true counts=[229, 221] pred counts=[35, 415]\n  Val per-class acc=[0.09170305728912354, 0.9366515874862671]\nEpoch 028/200 | Train loss=0.6977 acc=0.5123 | Val loss=0.6934 acc=0.5333\n  Val true counts=[229, 221] pred counts=[249, 201]\n  Val per-class acc=[0.5851528644561768, 0.479638010263443]\nEpoch 029/200 | Train loss=0.6936 acc=0.5174 | Val loss=0.6951 acc=0.5067\n  Val true counts=[229, 221] pred counts=[449, 1]\n  Val per-class acc=[0.9956331849098206, 0.0]\nEpoch 030/200 | Train loss=0.6946 acc=0.4877 | Val loss=0.6933 acc=0.5111\n  Val true counts=[229, 221] pred counts=[265, 185]\n  Val per-class acc=[0.5982532501220703, 0.42081448435783386]\nEpoch 031/200 | Train loss=0.6968 acc=0.5066 | Val loss=0.6932 acc=0.5156\n  Val true counts=[229, 221] pred counts=[69, 381]\n  Val per-class acc=[0.17467248439788818, 0.8687782883644104]\nEpoch 032/200 | Train loss=0.6935 acc=0.5066 | Val loss=0.6934 acc=0.5289\n  Val true counts=[229, 221] pred counts=[161, 289]\n  Val per-class acc=[0.38864627480506897, 0.6742081642150879]\nEpoch 033/200 | Train loss=0.6994 acc=0.4900 | Val loss=0.6928 acc=0.5333\n  Val true counts=[229, 221] pred counts=[269, 181]\n  Val per-class acc=[0.6288209557533264, 0.4343891441822052]\nEpoch 034/200 | Train loss=0.6952 acc=0.5020 | Val loss=0.6929 acc=0.5133\n  Val true counts=[229, 221] pred counts=[340, 110]\n  Val per-class acc=[0.7641921639442444, 0.25339367985725403]\nEpoch 035/200 | Train loss=0.6955 acc=0.4883 | Val loss=0.6927 acc=0.5400\n  Val true counts=[229, 221] pred counts=[268, 182]\n  Val per-class acc=[0.6331877708435059, 0.44343891739845276]\n  New best (0.5400) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 036/200 | Train loss=0.6974 acc=0.5111 | Val loss=0.6930 acc=0.5111\n  Val true counts=[229, 221] pred counts=[431, 19]\n  Val per-class acc=[0.960698664188385, 0.04524886980652809]\nEpoch 037/200 | Train loss=0.6927 acc=0.4980 | Val loss=0.6942 acc=0.4956\n  Val true counts=[229, 221] pred counts=[8, 442]\n  Val per-class acc=[0.021834060549736023, 0.9864253401756287]\nEpoch 038/200 | Train loss=0.6974 acc=0.4929 | Val loss=0.6931 acc=0.5378\n  Val true counts=[229, 221] pred counts=[213, 237]\n  Val per-class acc=[0.5109170079231262, 0.5656108856201172]\nEpoch 039/200 | Train loss=0.6915 acc=0.5333 | Val loss=0.6934 acc=0.5000\n  Val true counts=[229, 221] pred counts=[376, 74]\n  Val per-class acc=[0.8296943306922913, 0.15837104618549347]\nEpoch 040/200 | Train loss=0.6917 acc=0.5179 | Val loss=0.6947 acc=0.4978\n  Val true counts=[229, 221] pred counts=[11, 439]\n  Val per-class acc=[0.030567685142159462, 0.9819004535675049]\nEpoch 041/200 | Train loss=0.6961 acc=0.5043 | Val loss=0.6936 acc=0.5067\n  Val true counts=[229, 221] pred counts=[433, 17]\n  Val per-class acc=[0.960698664188385, 0.03619909659028053]\nEpoch 042/200 | Train loss=0.6935 acc=0.5225 | Val loss=0.6934 acc=0.5200\n  Val true counts=[229, 221] pred counts=[187, 263]\n  Val per-class acc=[0.43668121099472046, 0.6063348650932312]\nEpoch 043/200 | Train loss=0.6932 acc=0.5254 | Val loss=0.6933 acc=0.5556\n  Val true counts=[229, 221] pred counts=[229, 221]\n  Val per-class acc=[0.5633187890052795, 0.5475113391876221]\n  New best (0.5556) saved to /kaggle/working/models/labram_probe/labram_probe_best.pth\nEpoch 044/200 | Train loss=0.6920 acc=0.5094 | Val loss=0.6932 acc=0.5044\n  Val true counts=[229, 221] pred counts=[344, 106]\n  Val per-class acc=[0.7641921639442444, 0.23529411852359772]\nEpoch 045/200 | Train loss=0.6925 acc=0.5179 | Val loss=0.6935 acc=0.5089\n  Val true counts=[229, 221] pred counts=[352, 98]\n  Val per-class acc=[0.7860261797904968, 0.22171945869922638]\nEpoch 046/200 | Train loss=0.6934 acc=0.5020 | Val loss=0.6950 acc=0.5156\n  Val true counts=[229, 221] pred counts=[435, 15]\n  Val per-class acc=[0.9737991094589233, 0.04072398319840431]\nEpoch 047/200 | Train loss=0.6939 acc=0.5128 | Val loss=0.6933 acc=0.5356\n  Val true counts=[229, 221] pred counts=[252, 198]\n  Val per-class acc=[0.5938864350318909, 0.4751131236553192]\nEpoch 048/200 | Train loss=0.6937 acc=0.5083 | Val loss=0.6950 acc=0.5022\n  Val true counts=[229, 221] pred counts=[445, 5]\n  Val per-class acc=[0.9825327396392822, 0.004524887073785067]\nEpoch 049/200 | Train loss=0.6939 acc=0.5197 | Val loss=0.6941 acc=0.5244\n  Val true counts=[229, 221] pred counts=[77, 373]\n  Val per-class acc=[0.20087336003780365, 0.8597285151481628]\nEpoch 050/200 | Train loss=0.6940 acc=0.5066 | Val loss=0.6929 acc=0.5133\n  Val true counts=[229, 221] pred counts=[244, 206]\n  Val per-class acc=[0.5545851588249207, 0.47058823704719543]\nEpoch 051/200 | Train loss=0.6912 acc=0.5214 | Val loss=0.6931 acc=0.5133\n  Val true counts=[229, 221] pred counts=[374, 76]\n  Val per-class acc=[0.8384279608726501, 0.1764705926179886]\nEpoch 052/200 | Train loss=0.6916 acc=0.5248 | Val loss=0.6931 acc=0.5022\n  Val true counts=[229, 221] pred counts=[351, 99]\n  Val per-class acc=[0.7772925496101379, 0.2171945720911026]\nEpoch 053/200 | Train loss=0.6932 acc=0.5231 | Val loss=0.6939 acc=0.5133\n  Val true counts=[229, 221] pred counts=[144, 306]\n  Val per-class acc=[0.3362445533275604, 0.6968325972557068]\nEpoch 054/200 | Train loss=0.6936 acc=0.5185 | Val loss=0.6934 acc=0.5067\n  Val true counts=[229, 221] pred counts=[331, 119]\n  Val per-class acc=[0.7379912734031677, 0.26696833968162537]\nEpoch 055/200 | Train loss=0.6950 acc=0.5077 | Val loss=0.6936 acc=0.5200\n  Val true counts=[229, 221] pred counts=[189, 261]\n  Val per-class acc=[0.4410480260848999, 0.6018099784851074]\nEpoch 056/200 | Train loss=0.6913 acc=0.5328 | Val loss=0.6933 acc=0.5200\n  Val true counts=[229, 221] pred counts=[295, 155]\n  Val per-class acc=[0.6724891066551208, 0.36199095845222473]\nEpoch 057/200 | Train loss=0.6918 acc=0.5299 | Val loss=0.6933 acc=0.5044\n  Val true counts=[229, 221] pred counts=[372, 78]\n  Val per-class acc=[0.8253275156021118, 0.1719457060098648]\nEpoch 058/200 | Train loss=0.6924 acc=0.5219 | Val loss=0.6941 acc=0.5156\n  Val true counts=[229, 221] pred counts=[129, 321]\n  Val per-class acc=[0.3056768476963043, 0.733031690120697]\nEpoch 059/200 | Train loss=0.6908 acc=0.5185 | Val loss=0.6936 acc=0.5222\n  Val true counts=[229, 221] pred counts=[238, 212]\n  Val per-class acc=[0.5502183437347412, 0.49321267008781433]\nEpoch 060/200 | Train loss=0.6912 acc=0.5282 | Val loss=0.6936 acc=0.5156\n  Val true counts=[229, 221] pred counts=[399, 51]\n  Val per-class acc=[0.8951964974403381, 0.12217194586992264]\nEpoch 061/200 | Train loss=0.6925 acc=0.5231 | Val loss=0.6932 acc=0.5067\n  Val true counts=[229, 221] pred counts=[349, 101]\n  Val per-class acc=[0.7772925496101379, 0.22624434530735016]\nEpoch 062/200 | Train loss=0.6903 acc=0.5356 | Val loss=0.6937 acc=0.5422\n  Val true counts=[229, 221] pred counts=[233, 217]\n  Val per-class acc=[0.5589519739151001, 0.5248869061470032]\nEpoch 063/200 | Train loss=0.6928 acc=0.5134 | Val loss=0.6935 acc=0.5089\n  Val true counts=[229, 221] pred counts=[356, 94]\n  Val per-class acc=[0.7947598099708557, 0.21266968548297882]\nEpoch 064/200 | Train loss=0.6895 acc=0.5305 | Val loss=0.6940 acc=0.5200\n  Val true counts=[229, 221] pred counts=[185, 265]\n  Val per-class acc=[0.432314395904541, 0.610859751701355]\nEpoch 065/200 | Train loss=0.6901 acc=0.5362 | Val loss=0.6950 acc=0.5022\n  Val true counts=[229, 221] pred counts=[91, 359]\n  Val per-class acc=[0.20960699021816254, 0.8054298758506775]\nEpoch 066/200 | Train loss=0.6902 acc=0.5299 | Val loss=0.6933 acc=0.5200\n  Val true counts=[229, 221] pred counts=[339, 111]\n  Val per-class acc=[0.7685589790344238, 0.2624434530735016]\nEpoch 067/200 | Train loss=0.6898 acc=0.5316 | Val loss=0.6932 acc=0.5222\n  Val true counts=[229, 221] pred counts=[196, 254]\n  Val per-class acc=[0.4585152864456177, 0.5882353186607361]\nEpoch 068/200 | Train loss=0.6889 acc=0.5493 | Val loss=0.6940 acc=0.5133\n  Val true counts=[229, 221] pred counts=[398, 52]\n  Val per-class acc=[0.8908296823501587, 0.12217194586992264]\nEpoch 069/200 | Train loss=0.6893 acc=0.5276 | Val loss=0.6964 acc=0.5133\n  Val true counts=[229, 221] pred counts=[438, 12]\n  Val per-class acc=[0.9781659245491028, 0.031674209982156754]\nEpoch 070/200 | Train loss=0.6896 acc=0.5299 | Val loss=0.6937 acc=0.5289\n  Val true counts=[229, 221] pred counts=[231, 219]\n  Val per-class acc=[0.5414847135543823, 0.5158371329307556]\nEpoch 071/200 | Train loss=0.6889 acc=0.5305 | Val loss=0.6958 acc=0.5133\n  Val true counts=[229, 221] pred counts=[424, 26]\n  Val per-class acc=[0.9475982785224915, 0.06334841996431351]\nEpoch 072/200 | Train loss=0.6884 acc=0.5493 | Val loss=0.6933 acc=0.5356\n  Val true counts=[229, 221] pred counts=[306, 144]\n  Val per-class acc=[0.7117903828620911, 0.3529411852359772]\nEpoch 073/200 | Train loss=0.6879 acc=0.5385 | Val loss=0.6942 acc=0.5022\n  Val true counts=[229, 221] pred counts=[145, 305]\n  Val per-class acc=[0.32751092314720154, 0.6832579374313354]\nEpoch 074/200 | Train loss=0.6864 acc=0.5447 | Val loss=0.6929 acc=0.5356\n  Val true counts=[229, 221] pred counts=[244, 206]\n  Val per-class acc=[0.5764192342758179, 0.49321267008781433]\nEpoch 075/200 | Train loss=0.6881 acc=0.5487 | Val loss=0.6947 acc=0.5067\n  Val true counts=[229, 221] pred counts=[123, 327]\n  Val per-class acc=[0.2838428020477295, 0.7375565767288208]\nEpoch 076/200 | Train loss=0.6847 acc=0.5499 | Val loss=0.6931 acc=0.5467\n  Val true counts=[229, 221] pred counts=[257, 193]\n  Val per-class acc=[0.6157205104827881, 0.4751131236553192]\nEpoch 077/200 | Train loss=0.6888 acc=0.5311 | Val loss=0.6930 acc=0.5400\n  Val true counts=[229, 221] pred counts=[236, 214]\n  Val per-class acc=[0.5633187890052795, 0.5158371329307556]\nEpoch 078/200 | Train loss=0.6848 acc=0.5766 | Val loss=0.6937 acc=0.5289\n  Val true counts=[229, 221] pred counts=[185, 265]\n  Val per-class acc=[0.4410480260848999, 0.6199095249176025]\nEpoch 079/200 | Train loss=0.6821 acc=0.5652 | Val loss=0.6951 acc=0.5111\n  Val true counts=[229, 221] pred counts=[377, 73]\n  Val per-class acc=[0.8427947759628296, 0.16742081940174103]\nEpoch 080/200 | Train loss=0.6853 acc=0.5550 | Val loss=0.6953 acc=0.5156\n  Val true counts=[229, 221] pred counts=[373, 77]\n  Val per-class acc=[0.8384279608726501, 0.18099547922611237]\nEpoch 081/200 | Train loss=0.6853 acc=0.5447 | Val loss=0.6973 acc=0.5133\n  Val true counts=[229, 221] pred counts=[402, 48]\n  Val per-class acc=[0.8995633125305176, 0.11312217265367508]\nEpoch 082/200 | Train loss=0.6831 acc=0.5573 | Val loss=0.6940 acc=0.5556\n  Val true counts=[229, 221] pred counts=[277, 173]\n  Val per-class acc=[0.6681222915649414, 0.438914030790329]\nEpoch 083/200 | Train loss=0.6838 acc=0.5402 | Val loss=0.6975 acc=0.5089\n  Val true counts=[229, 221] pred counts=[398, 52]\n  Val per-class acc=[0.8864628672599792, 0.11764705926179886]\n\nEarly stopping at epoch 83.\n\nTraining complete. Best val acc: 0.5556\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import silhouette_score\n\ndef extract_labram_embeddings(model, X_tensor, batch_size=256):\n    model.eval()\n    device = next(model.parameters()).device\n    feats = []\n    loader = DataLoader(TensorDataset(X_tensor), batch_size=batch_size, shuffle=False)\n    with torch.no_grad():\n        for (xb,) in loader:\n            xb = xb.to(device)\n            z = model.encode(xb, force_no_grad=True)  # shape: (B, 200)\n            feats.append(z.cpu().numpy())\n    return np.concatenate(feats, axis=0)\n\ndef stratified_subsample(X, y, max_per_class=400, seed=42):\n    rng = np.random.default_rng(seed)\n    y = np.asarray(y)\n    idx = []\n    for c in np.unique(y):\n        c_idx = np.where(y == c)[0]\n        take = min(max_per_class, len(c_idx))\n        idx.extend(rng.choice(c_idx, size=take, replace=False))\n    idx = np.array(idx)\n    rng.shuffle(idx)\n    return X[idx], y[idx]\n\n# 1) Extract embeddings\nemb_train = extract_labram_embeddings(model, X_train_t, batch_size=256)\nemb_val = extract_labram_embeddings(model, X_val_t, batch_size=256)\ny_train_np = y_train_t.cpu().numpy()\ny_val_np = y_val_t.cpu().numpy()\n\n# 2) Optional balanced subsample for cleaner/faster plots\nemb_train_s, y_train_s = stratified_subsample(emb_train, y_train_np, max_per_class=400, seed=1)\nemb_val_s, y_val_s = stratified_subsample(emb_val, y_val_np, max_per_class=400, seed=2)\n\nX_all = np.vstack([emb_train_s, emb_val_s])\ny_all = np.concatenate([y_train_s, y_val_s])\nsplit_all = np.array([\"train\"] * len(emb_train_s) + [\"val\"] * len(emb_val_s))\n\n# 3) Standardize features\nscaler = StandardScaler()\nX_all_std = scaler.fit_transform(X_all)\n\n# 4) PCA\npca = PCA(n_components=2, random_state=42)\nX_pca = pca.fit_transform(X_all_std)\n\n# 5) t-SNE\nn = len(X_all_std)\nperplexity = min(30, max(5, (n - 1) // 3))\ntsne = TSNE(\n  n_components=2,\n  perplexity=perplexity,\n  init=\"pca\",\n  learning_rate=\"auto\",\n  random_state=42,\n)\nX_tsne = tsne.fit_transform(X_all_std)\n\n# 6) Plot helper\ndef plot_2d(ax, Z, y, split, title):\n    classes = np.unique(y)\n    colors = plt.cm.tab10(np.linspace(0, 1, len(classes)))\n    marker_map = {\"train\": \"o\", \"val\": \"x\"}\n    for i, c in enumerate(classes):\n        for sp in [\"train\", \"val\"]:\n            mask = (y == c) & (split == sp)\n            if mask.any():\n                ax.scatter(\n                    Z[mask, 0],\n                    Z[mask, 1],\n                    s=22,\n                    alpha=0.7,\n                    marker=marker_map[sp],\n                    color=colors[i],\n                    label=f\"class {c} ({sp})\",\n                )\n    ax.set_title(title)\n    ax.set_xlabel(\"dim 1\")\n    ax.set_ylabel(\"dim 2\")\n    ax.legend(loc=\"best\", fontsize=8)\n\n# 7) Render\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nplot_2d(axes[0], X_pca, y_all, split_all, \"PCA of LaBraM Embeddings\")\nplot_2d(axes[1], X_tsne, y_all, split_all, f\"t-SNE of LaBraM Embeddings (perp={perplexity})\")\nplt.tight_layout()\nplt.show()\n\n# 8) Quick numeric sanity\nprint(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")\nif len(np.unique(y_all)) > 1:\n    print(\"Silhouette score (PCA 2D):\", silhouette_score(X_pca, y_all))\n    print(\"Silhouette score (t-SNE 2D):\", silhouette_score(X_tsne, y_all))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:49:15.853511Z","iopub.execute_input":"2026-02-28T06:49:15.854225Z","iopub.status.idle":"2026-02-28T06:49:32.983103Z","shell.execute_reply.started":"2026-02-28T06:49:15.854189Z","shell.execute_reply":"2026-02-28T06:49:32.982479Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"PCA explained variance ratio: [0.19062445 0.10972243]\nSilhouette score (PCA 2D): 0.0099735195\nSilhouette score (t-SNE 2D): 0.009950059\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}